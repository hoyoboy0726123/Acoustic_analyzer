# -*- coding: utf-8 -*-
"""
è²å­¸æ¸¬è©¦ AI åˆ†æç³»çµ± - Streamlit Web UI

åŠŸèƒ½ (AUD-009):
- æª”æ¡ˆä¸Šå‚³ä»‹é¢
- åˆ†æçµæœé¡¯ç¤º
- é »è­œåœ–è¦–è¦ºåŒ–
- å ±å‘Šä¸‹è¼‰
"""

import streamlit as st
import tempfile
import os
from pathlib import Path
import sys

# åŠ å…¥å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))


def main():
    """Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»å‡½æ•¸"""
    st.set_page_config(
        page_title="è²å­¸æ¸¬è©¦ AI åˆ†æç³»çµ±",
        page_icon="ğŸ”Š",
        layout="wide"
    )
    
    # åˆå§‹åŒ– session_state
    if 'audio_loaded' not in st.session_state:
        st.session_state.audio_loaded = False
    if 'audio_original' not in st.session_state:
        st.session_state.audio_original = None
    if 'sr' not in st.session_state:
        st.session_state.sr = None
    if 'validation' not in st.session_state:
        st.session_state.validation = None

    st.title("ğŸ”Š è²å­¸æ¸¬è©¦ AI åˆ†æç³»çµ±")
    st.markdown("*åŸºæ–¼ AI çš„ç­†è¨˜å‹é›»è…¦è²å­¸æ¸¬è©¦åˆ†æç³»çµ±*")
    st.markdown("---")

    # å´é‚Šæ¬„è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ åˆ†æè¨­å®š")
        
        highpass_cutoff = st.slider(
            "é«˜é€šæ¿¾æ³¢æˆªæ­¢é »ç‡ (Hz)",
            min_value=1000, max_value=8000, value=4000, step=500,
            help="ç”¨æ–¼é«˜é »éŸ³éš”é›¢åˆ†æ"
        )
        
        st.markdown("---")
        
        st.subheader("ğŸ“‹ åˆ†æé¸é …")
        analyze_noise = st.checkbox("å™ªéŸ³ç­‰ç´šåˆ†æ dB(A)", value=True)
        analyze_spectrum = st.checkbox("FFT é »è­œåˆ†æ", value=True)
        analyze_discrete_tone = st.checkbox("Discrete Tone æª¢æ¸¬", value=True)
        analyze_high_freq = st.checkbox("é«˜é »éŸ³éš”é›¢åˆ†æ", value=True)
        analyze_band_filter = st.checkbox("ğŸšï¸ é »å¸¶éæ¿¾æ¨¡æ“¬", value=False)
        
        # é »å¸¶é¸æ“‡å™¨
        removed_bands = []
        if analyze_band_filter:
            st.markdown("---")
            st.subheader("ğŸšï¸ é »å¸¶éæ¿¾æ¨¡æ“¬")
            st.caption("é¸æ“‡è¦ç§»é™¤çš„é »å¸¶ï¼Œæ¨¡æ“¬å»é™¤ç‰¹å®šå™ªéŸ³ä¾†æºçš„æ•ˆæœ")
            
            remove_low = st.checkbox("ç§»é™¤ä½é » (20-500Hz) - é¢¨æ‰‡/é¦¬é”", value=False, key="rm_low")
            remove_mid = st.checkbox("ç§»é™¤ä¸­é » (500-2kHz) - æ©Ÿæ¢°é‹è½‰", value=False, key="rm_mid")
            remove_mid_high = st.checkbox("ç§»é™¤ä¸­é«˜é » (2-6kHz) - éµç›¤è²", value=False, key="rm_mid_high")
            remove_high = st.checkbox("ç§»é™¤é«˜é » (6-12kHz) - é›»æ„Ÿå˜¯å«", value=False, key="rm_high")
            remove_ultra = st.checkbox("ç§»é™¤è¶…é«˜é » (12-20kHz)", value=False, key="rm_ultra")
            
            if remove_low:
                removed_bands.append("low_freq")
            if remove_mid:
                removed_bands.append("mid_freq")
            if remove_mid_high:
                removed_bands.append("mid_high_freq")
            if remove_high:
                removed_bands.append("high_freq")
            if remove_ultra:
                removed_bands.append("ultra_high_freq")
        
        st.markdown("---")
        st.caption("v1.0.0 | è²å­¸æ¸¬è©¦ AI åˆ†æç³»çµ±")

    # ä¸»è¦å…§å®¹å€
    st.header("ğŸ“ ä¸Šå‚³éŸ³æª”")
    
    uploaded_file = st.file_uploader(
        "é¸æ“‡è¦åˆ†æçš„éŸ³æª”",
        type=["wav", "mp3", "flac"],
        help="æ”¯æ´ WAVã€MP3ã€FLAC æ ¼å¼ï¼Œæª”æ¡ˆå¤§å°ä¸Šé™ 50MB"
    )

    if uploaded_file is not None:
        st.success(f"âœ… å·²ä¸Šå‚³: **{uploaded_file.name}** ({uploaded_file.size / 1024 / 1024:.2f} MB)")
        
        # é–‹å§‹åˆ†ææŒ‰éˆ• - åªè¼‰å…¥éŸ³æª”ä¸€æ¬¡
        if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True):
            load_audio_file(uploaded_file)
        
        # å¦‚æœéŸ³æª”å·²è¼‰å…¥ï¼Œæ ¹æ“šå´é‚Šæ¬„è¨­å®šå³æ™‚é¡¯ç¤ºåˆ†æçµæœ
        if st.session_state.audio_loaded:
            render_analysis_results(
                highpass_cutoff,
                analyze_noise,
                analyze_spectrum,
                analyze_discrete_tone,
                analyze_high_freq,
                analyze_band_filter,
                removed_bands
            )
    else:
        # æ¸…é™¤å·²è¼‰å…¥çš„éŸ³æª”
        st.session_state.audio_loaded = False
        st.session_state.audio_original = None
        
        st.info("ğŸ‘† è«‹ä¸Šå‚³éŸ³æª”ä»¥é–‹å§‹åˆ†æ")
        
        # é¡¯ç¤ºæ”¯æ´çš„è¦æ ¼
        with st.expander("ğŸ“Œ æ”¯æ´çš„éŸ³æª”è¦æ ¼"):
            st.markdown("""
            | é …ç›® | è¦æ ¼ |
            |------|------|
            | æ ¼å¼ | WAV (å¿…é ˆ), MP3, FLAC (å¯é¸) |
            | å–æ¨£ç‡ | 44100 æˆ– 48000 Hz |
            | ä½å…ƒæ·±åº¦ | 16-bit æˆ– 24-bit |
            | è²é“ | Mono (å–®è²é“) |
            | æª”æ¡ˆå¤§å° | â‰¤ 50 MB |
            | é•·åº¦ | 10 - 120 ç§’ |
            """)


def load_audio_file(uploaded_file):
    """è¼‰å…¥éŸ³æª”åˆ° session_state"""
    with st.spinner("ğŸ”„ æ­£åœ¨è¼‰å…¥ä¸¦é©—è­‰éŸ³æª”..."):
        from core.audio_loader import load_audio, validate_audio
        
        # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(
            suffix=f".{uploaded_file.name.split('.')[-1]}",
            delete=False
        ) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        try:
            # é©—è­‰éŸ³æª”
            validation = validate_audio(tmp_path, strict=False)
            
            if not validation["file_valid"]:
                st.error(f"âŒ éŸ³æª”é©—è­‰å¤±æ•—: {validation['error_message']}")
                return
            
            # è¼‰å…¥éŸ³æª”
            audio, sr = load_audio(tmp_path)
            
            # ä¿å­˜åˆ° session_state
            st.session_state.audio_original = audio
            st.session_state.sr = sr
            st.session_state.validation = validation
            st.session_state.audio_loaded = True
            
            st.rerun()  # é‡æ–°é‹è¡Œä»¥é¡¯ç¤ºåˆ†æçµæœ
            
        finally:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            os.unlink(tmp_path)


def render_analysis_results(highpass_cutoff, analyze_noise, analyze_spectrum, 
                            analyze_discrete_tone, analyze_high_freq, 
                            analyze_band_filter, removed_bands):
    """æ ¹æ“šå´é‚Šæ¬„è¨­å®šå³æ™‚æ¸²æŸ“åˆ†æçµæœ"""
    import numpy as np
    
    # å¾ session_state å–å¾—éŸ³è¨Šè³‡æ–™
    audio_original = st.session_state.audio_original
    sr = st.session_state.sr
    validation = st.session_state.validation
    
    if audio_original is None:
        return
    
    # å¥—ç”¨é »å¸¶éæ¿¾ (å¦‚æœå•Ÿç”¨)
    if analyze_band_filter and removed_bands:
        with st.spinner("ğŸšï¸ å¥—ç”¨é »å¸¶éæ¿¾..."):
            audio = apply_band_filter(audio_original, sr, removed_bands)
            st.info(f"ğŸšï¸ **é »å¸¶éæ¿¾å·²å•Ÿç”¨**: å·²ç§»é™¤ {len(removed_bands)} å€‹é »å¸¶ï¼Œä»¥ä¸‹æ‰€æœ‰åˆ†æåŸºæ–¼éæ¿¾å¾Œçš„éŸ³è¨Š")
    else:
        audio = audio_original
    
    # é¡¯ç¤ºéŸ³æª”è³‡è¨Š
    display_audio_info(validation)
    
    # åŸ·è¡Œå„é …åˆ†æ (ä½¿ç”¨éæ¿¾å¾Œçš„éŸ³è¨Š)
    if analyze_noise:
        run_noise_analysis(audio, sr)

    if analyze_spectrum:
        run_spectrum_analysis(audio, sr)

    if analyze_discrete_tone:
        run_discrete_tone_analysis(audio, sr)

    if analyze_high_freq:
        run_high_freq_analysis(audio, sr, highpass_cutoff)

    # å¦‚æœæœ‰é »å¸¶éæ¿¾ï¼Œé¡¯ç¤ºåŸå§‹ vs éæ¿¾å¾Œå°æ¯”
    if analyze_band_filter and removed_bands:
        run_band_filter_comparison(audio_original, audio, sr, removed_bands)

    st.success("âœ… åˆ†æå®Œæˆï¼å´é‚Šæ¬„èª¿æ•´è¨­å®šæœƒå³æ™‚æ›´æ–°åœ–è¡¨ã€‚")



def display_audio_info(validation: dict):
    """é¡¯ç¤ºéŸ³æª”è³‡è¨Š"""
    st.subheader("ğŸ“Š éŸ³æª”è³‡è¨Š")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("å–æ¨£ç‡", f"{validation['sample_rate']} Hz")
    with col2:
        st.metric("é•·åº¦", f"{validation['duration']:.2f} ç§’")
    with col3:
        st.metric("ä½å…ƒæ·±åº¦", f"{validation['bit_depth']}-bit")
    with col4:
        st.metric("æª”æ¡ˆå¤§å°", f"{validation['file_size_mb']:.2f} MB")
    
    if validation.get("warnings"):
        for warning in validation["warnings"]:
            st.warning(f"âš ï¸ {warning}")


def run_noise_analysis(audio, sr):
    """åŸ·è¡Œå™ªéŸ³ç­‰ç´šåˆ†æ"""
    from core.noise_level import calculate_noise_level
    
    result = calculate_noise_level(audio, sr)
    
    st.subheader("ğŸ”Š å™ªéŸ³ç­‰ç´šåˆ†æ dB(A)")
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("Leq", f"{result['leq_dba']:.1f} dB")
    with col2:
        st.metric("Lmax", f"{result['lmax_dba']:.1f} dB")
    with col3:
        st.metric("Lmin", f"{result['lmin_dba']:.1f} dB")
    with col4:
        st.metric("L10", f"{result['l10']:.1f} dB")
    with col5:
        st.metric("L90", f"{result['l90']:.1f} dB")
    
    st.markdown("---")


def run_spectrum_analysis(audio, sr):
    """åŸ·è¡Œé »è­œåˆ†æ - å¤šç¨®åœ–è¡¨å³æ™‚åˆ‡æ›"""
    from core.fft import compute_average_spectrum
    from utils.interactive_plots import (
        create_interactive_spectrum,
        create_waveform_chart,
        create_spectrogram_chart,
        create_a_weighting_chart,
        create_octave_band_chart,
        create_waterfall_3d_chart,
        create_combined_analysis_chart
    )
    import numpy as np
    
    # è¨ˆç®—é »è­œ (åªéœ€è¨ˆç®—ä¸€æ¬¡)
    frequencies, magnitudes_db = compute_average_spectrum(audio, sr)
    
    # å°‡çµæœå­˜å…¥ session_state ä¾›åœ–è¡¨åˆ‡æ›ä½¿ç”¨
    st.session_state['audio'] = audio
    st.session_state['sr'] = sr
    st.session_state['frequencies'] = frequencies
    st.session_state['magnitudes_db'] = magnitudes_db
    
    st.subheader("ğŸ“ˆ é »è­œåˆ†æ (å¤šç¨®è¦–åœ–)")
    st.caption("ğŸ’¡ æç¤º: åˆ‡æ›ä¸åŒåœ–è¡¨é¡å‹å³æ™‚é¡¯ç¤ºï¼Œæ”¯æ´æ»‘é¼ ç¸®æ”¾ã€å¹³ç§»ã€åå­—åº§æ¨™")
    
    # ä½¿ç”¨ tabs å¯¦ç¾å³æ™‚åˆ‡æ›
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“Š FFT é »è­œ", 
        "ğŸŒŠ æ³¢å½¢åœ–", 
        "ğŸ”¥ Spectrogram", 
        "ğŸ‘‚ A-weighting", 
        "ğŸ“¶ 1/3 å€é »ç¨‹",
        "ğŸŒ€ 3D Waterfall",
        "ğŸ“‹ ç¶œåˆè¦–åœ–"
    ])
    
    with tab1:
        spectrum_fig = create_interactive_spectrum(
            frequencies, magnitudes_db,
            title="FFT å¹³å‡é »è­œåœ–"
        )
        st.plotly_chart(spectrum_fig, use_container_width=True, key="fft_spectrum")
    
    with tab2:
        waveform_fig = create_waveform_chart(audio, sr)
        st.plotly_chart(waveform_fig, use_container_width=True, key="waveform")
    
    with tab3:
        spectrogram_fig = create_spectrogram_chart(audio, sr)
        st.plotly_chart(spectrogram_fig, use_container_width=True, key="spectrogram")
    
    with tab4:
        a_weight_fig = create_a_weighting_chart(sr)
        st.plotly_chart(a_weight_fig, use_container_width=True, key="a_weight")
        st.info("ğŸ’¡ A-weighting æ›²ç·šé¡¯ç¤ºäººè€³å°ä¸åŒé »ç‡çš„æ•æ„Ÿåº¦ã€‚ä½é »å’Œè¶…é«˜é »æœƒè¢«è¡°æ¸›ï¼Œ2-5kHz å€åŸŸï¼ˆäººè€³æœ€æ•æ„Ÿï¼‰å‰‡æ¥è¿‘ 0 dBã€‚")
    
    with tab5:
        octave_fig = create_octave_band_chart(audio, sr)
        st.plotly_chart(octave_fig, use_container_width=True, key="octave")
        st.info("ğŸ’¡ 1/3 å€é »ç¨‹åˆ†æä¾ ISO æ¨™æº–å°‡é »è­œåˆ†æˆæ¨™æº–é »å¸¶ï¼Œå¸¸ç”¨æ–¼å™ªéŸ³è©•ä¼°å’Œè²å­¸æ¸¬é‡ã€‚")
    
    with tab6:
        waterfall_fig = create_waterfall_3d_chart(audio, sr)
        st.plotly_chart(waterfall_fig, use_container_width=True, key="waterfall")
        st.info("ğŸ’¡ 3D Waterfall åœ–å¯æ—‹è½‰ã€ç¸®æ”¾ã€‚æ‹–æ›³å¯æ”¹è®Šè¦–è§’ï¼Œæ»¾è¼ªç¸®æ”¾ã€‚")
    
    with tab7:
        combined_fig = create_combined_analysis_chart(audio, sr, frequencies, magnitudes_db)
        st.plotly_chart(combined_fig, use_container_width=True, key="combined")
    
    st.markdown("---")


def run_discrete_tone_analysis(audio, sr):
    """åŸ·è¡Œ Discrete Tone æª¢æ¸¬"""
    from core.discrete_tone import detect_discrete_tones
    from core.fft import compute_average_spectrum, get_frequency_range
    from utils.interactive_plots import create_discrete_tone_chart
    
    result = detect_discrete_tones(audio, sr)
    
    st.subheader("ğŸµ Discrete Tone æª¢æ¸¬ (ECMA-74)")
    st.caption("ğŸ’¡ æç¤º: ç´…è‰²æ˜Ÿè™Ÿæ¨™è¨˜è¶…éé–€æª»çš„ Discrete Toneï¼Œç°è‰²ä¸‰è§’å½¢ç‚ºå€™é¸å³°å€¼")
    
    # è¨ˆç®—é »è­œç”¨æ–¼è¦–è¦ºåŒ–
    frequencies, magnitudes_db = compute_average_spectrum(audio, sr)
    frequencies, magnitudes_db = get_frequency_range(frequencies, magnitudes_db, 50, 15000)
    
    # ç¹ªè£½ Discrete Tone è¦–è¦ºåŒ–åœ–è¡¨
    tone_fig = create_discrete_tone_chart(
        frequencies, magnitudes_db,
        tones=result.get("tones", []),
        all_candidates=result.get("all_candidates", []),
        title="Discrete Tone æª¢æ¸¬çµæœ (ECMA-74 æ¨™æº–)"
    )
    st.plotly_chart(tone_fig, use_container_width=True)
    
    # ç‹€æ…‹é¡¯ç¤º
    if result["tone_detected"]:
        st.warning(f"âš ï¸ åµæ¸¬åˆ° {len(result['tones'])} å€‹ Discrete Tone!")
        
        # é¡¯ç¤ºåµæ¸¬åˆ°çš„ Tone
        for i, tone in enumerate(result["tones"], 1):
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric(f"Tone #{i} é »ç‡", f"{tone['frequency']:.0f} Hz")
            with col2:
                st.metric("çªå‡ºé‡", f"{tone['prominence']:.1f} dB")
            with col3:
                st.metric("é–€æª»", f"{tone['threshold']:.0f} dB")
            with col4:
                st.metric("é »å¸¶", tone['band'])
    else:
        st.success("âœ… æœªåµæ¸¬åˆ°è¶…éé–€æª»çš„ Discrete Tone")
    
    # é¡¯ç¤ºå€™é¸ Tone
    if result.get("all_candidates"):
        with st.expander("ğŸ” æŸ¥çœ‹æ‰€æœ‰å€™é¸å³°å€¼"):
            import pandas as pd
            df = pd.DataFrame(result["all_candidates"])
            if not df.empty:
                df.columns = ["é »ç‡ (Hz)", "çªå‡ºé‡ (dB)", "å¹…åº¦ (dB)", "é »å¸¶", "é–€æª» (dB)", "è¶…éé–€æª»"]
                st.dataframe(df, use_container_width=True)
    
    st.markdown("---")


def run_high_freq_analysis(audio, sr, cutoff):
    """åŸ·è¡Œé«˜é »éŸ³éš”é›¢åˆ†æ"""
    from core.high_freq_detector import analyze_high_frequency
    from core.fft import compute_average_spectrum, get_frequency_range
    from core.filters import highpass_filter
    from utils.interactive_plots import (
        create_comparison_spectrum,
        create_dual_spectrum_comparison,
        create_band_energy_chart
    )
    import numpy as np
    
    result = analyze_high_frequency(audio, sr, cutoff)
    
    st.subheader("âš¡ é«˜é »éŸ³éš”é›¢åˆ†æ")
    
    # æ•´é«”ç‹€æ…‹
    status = result["overall_status"]
    status_colors = {"PASS": "green", "WARNING": "orange", "FAIL": "red"}
    status_icons = {"PASS": "âœ…", "WARNING": "âš ï¸", "FAIL": "âŒ"}
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ•´é«”ç‹€æ…‹", f"{status_icons[status]} {status}")
    with col2:
        st.metric("æˆªæ­¢é »ç‡", f"{cutoff} Hz")
    with col3:
        coil_status = "åµæ¸¬åˆ°" if result["coil_whine_detected"] else "æœªåµæ¸¬"
        st.metric("é›»æ„Ÿå˜¯å«", coil_status)
    
    # é›»æ„Ÿå˜¯å«æª¢æ¸¬çµæœ
    if result["coil_whine_detected"]:
        st.error(
            f"ğŸ”” **åµæ¸¬åˆ°é›»æ„Ÿå˜¯å«!**\n\n"
            f"- é »ç‡: {result['coil_whine_frequency']:.0f} Hz\n"
            f"- çªå‡ºé‡: {result['coil_whine_prominence']:.1f} dB\n"
            f"- å¯èƒ½åŸå› : {result['possible_cause']}"
        )
    
    # å»ºè­°
    st.info(f"ğŸ’¡ **å»ºè­°:** {result['recommendation']}")
    
    # === æ¿¾æ³¢å‰å¾Œå°æ¯”åœ– (äº’å‹•å¼) ===
    st.subheader("ğŸ“Š æ¿¾æ³¢å‰å¾Œé »è­œå°æ¯” (å¯ç¸®æ”¾)")
    st.caption("ğŸ’¡ æç¤º: æ»‘é¼ æ»¾è¼ªç¸®æ”¾ã€æ‹–æ›³å¹³ç§»ã€é›™æ“Šé‡ç½®ã€æ»‘é¼ ç§»å‹•é¡¯ç¤ºåå­—åº§æ¨™")
    
    # è¨ˆç®—åŸå§‹é »è­œ
    freqs_orig, mags_orig = compute_average_spectrum(audio, sr)
    
    # è¨ˆç®—æ¿¾æ³¢å¾Œé »è­œ
    audio_filtered = highpass_filter(audio, sr, cutoff)
    freqs_filt, mags_filt = compute_average_spectrum(audio_filtered, sr)
    
    # é™åˆ¶é¡¯ç¤ºç¯„åœ
    freq_min, freq_max = 20, min(20000, sr // 2)
    freqs_orig, mags_orig = get_frequency_range(freqs_orig, mags_orig, freq_min, freq_max)
    freqs_filt, mags_filt = get_frequency_range(freqs_filt, mags_filt, freq_min, freq_max)
    
    # ç¹ªè£½äº’å‹•å¼å°æ¯”åœ–
    comparison_fig = create_comparison_spectrum(
        freqs_orig, mags_orig, mags_filt, cutoff,
        title=f"é«˜é€šæ¿¾æ³¢å‰å¾Œå°æ¯” (æˆªæ­¢é »ç‡: {cutoff} Hz)"
    )
    st.plotly_chart(comparison_fig, use_container_width=True)
    
    # åˆ†é–‹é¡¯ç¤ºåŸå§‹å’Œæ¿¾æ³¢å¾Œé »è­œ (äº’å‹•å¼é›™æ¬„)
    st.subheader("ğŸ“ˆ åŸå§‹ vs æ¿¾æ³¢å¾Œé »è­œå°æ¯”")
    dual_fig = create_dual_spectrum_comparison(
        freqs_orig, mags_orig,
        freqs_filt, mags_filt,
        title1="åŸå§‹é »è­œ (å…¨é »å¸¶)",
        title2=f"é«˜é€šæ¿¾æ³¢å¾Œ (>{cutoff} Hz)"
    )
    st.plotly_chart(dual_fig, use_container_width=True)
    
    # é »å¸¶èƒ½é‡åˆ†æåœ– (äº’å‹•å¼)
    st.subheader("ğŸ“Š é »å¸¶èƒ½é‡åˆ†æ")
    if result.get("band_analysis"):
        band_fig = create_band_energy_chart(result["band_analysis"])
        st.plotly_chart(band_fig, use_container_width=True)
    
    # é«˜é »å³°å€¼åˆ—è¡¨
    if result.get("high_freq_peaks"):
        with st.expander("ğŸ” æŸ¥çœ‹é«˜é »å³°å€¼è©³æƒ…"):
            import pandas as pd
            peaks_df = pd.DataFrame(result["high_freq_peaks"])
            if not peaks_df.empty:
                peaks_df.columns = ["é »ç‡ (Hz)", "å¹…åº¦ (dB)", "çªå‡ºé‡ (dB)"]
                st.dataframe(peaks_df, use_container_width=True)
            else:
                st.info("ç„¡æ˜é¡¯é«˜é »å³°å€¼")
    
    st.markdown("---")


def run_band_filter_analysis(audio, sr, removed_bands):
    """åŸ·è¡Œé »å¸¶éæ¿¾æ¨¡æ“¬åˆ†æ"""
    from core.fft import compute_average_spectrum, get_frequency_range
    from core.filters import bandpass_filter
    from core.noise_level import calculate_rms, rms_to_db
    from utils.interactive_plots import create_band_filter_comparison
    import numpy as np
    
    st.subheader("ğŸšï¸ é »å¸¶éæ¿¾æ¨¡æ“¬")
    st.caption("æ¨¡æ“¬ç§»é™¤ç‰¹å®šé »å¸¶å¾Œçš„é »è­œè®ŠåŒ–")
    
    # é »å¸¶å®šç¾©
    band_ranges = {
        'low_freq': (20, 500),
        'mid_freq': (500, 2000),
        'mid_high_freq': (2000, 6000),
        'high_freq': (6000, 12000),
        'ultra_high_freq': (12000, 20000)
    }
    
    band_names = {
        'low_freq': 'ä½é » (é¢¨æ‰‡/é¦¬é”)',
        'mid_freq': 'ä¸­é » (æ©Ÿæ¢°é‹è½‰)',
        'mid_high_freq': 'ä¸­é«˜é » (éµç›¤è²)',
        'high_freq': 'é«˜é » (é›»æ„Ÿå˜¯å«)',
        'ultra_high_freq': 'è¶…é«˜é »'
    }
    
    # é¡¯ç¤ºç§»é™¤çš„é »å¸¶
    st.info(f"ğŸ”‡ å·²ç§»é™¤çš„é »å¸¶: {', '.join([band_names.get(b, b) for b in removed_bands])}")
    
    # è¨ˆç®—åŸå§‹é »è­œ
    freqs_orig, mags_orig = compute_average_spectrum(audio, sr)
    
    # å»ºç«‹éæ¿¾å¾Œçš„è¨Šè™Ÿ (é€šéä¿ç•™æœªè¢«ç§»é™¤çš„é »å¸¶)
    nyquist = sr / 2
    audio_filtered = np.zeros_like(audio)
    
    for band_name, (low, high) in band_ranges.items():
        if band_name not in removed_bands:
            # ç¢ºä¿é »ç‡åœ¨æœ‰æ•ˆç¯„åœå…§
            low = max(20, low)
            high = min(high, nyquist - 1)
            if low < high:
                try:
                    band_audio = bandpass_filter(audio, sr, low, high)
                    audio_filtered += band_audio
                except:
                    pass
    
    # è¨ˆç®—éæ¿¾å¾Œé »è­œ
    freqs_filt, mags_filt = compute_average_spectrum(audio_filtered, sr)
    
    # é™åˆ¶é¡¯ç¤ºç¯„åœ
    freq_min, freq_max = 20, min(20000, sr // 2)
    freqs_orig, mags_orig = get_frequency_range(freqs_orig, mags_orig, freq_min, freq_max)
    freqs_filt, mags_filt = get_frequency_range(freqs_filt, mags_filt, freq_min, freq_max)
    
    # ç¹ªè£½äº’å‹•å¼å°æ¯”åœ–
    filter_fig = create_band_filter_comparison(
        freqs_orig, mags_orig, mags_filt, removed_bands,
        title="é »å¸¶éæ¿¾å‰å¾Œå°æ¯”"
    )
    st.plotly_chart(filter_fig, use_container_width=True)
    
    # è¨ˆç®—èƒ½é‡è®ŠåŒ–
    col1, col2, col3 = st.columns(3)
    
    rms_orig = calculate_rms(audio)
    rms_filt = calculate_rms(audio_filtered)
    db_orig = rms_to_db(rms_orig, 1.0)
    db_filt = rms_to_db(rms_filt, 1.0)
    db_reduction = db_orig - db_filt
    
    with col1:
        st.metric("åŸå§‹èƒ½é‡", f"{db_orig:.1f} dB")
    with col2:
        st.metric("éæ¿¾å¾Œèƒ½é‡", f"{db_filt:.1f} dB")
    with col3:
        st.metric("èƒ½é‡é™ä½", f"{db_reduction:.1f} dB", delta=f"-{db_reduction:.1f}")
    
    st.markdown("---")


def apply_band_filter(audio, sr, removed_bands):
    """å¥—ç”¨é »å¸¶éæ¿¾ï¼Œç§»é™¤æŒ‡å®šé »å¸¶
    
    Args:
        audio: åŸå§‹éŸ³è¨Šè³‡æ–™
        sr: å–æ¨£ç‡
        removed_bands: è¦ç§»é™¤çš„é »å¸¶åˆ—è¡¨
    
    Returns:
        éæ¿¾å¾Œçš„éŸ³è¨Šè³‡æ–™
    """
    from core.filters import bandpass_filter
    import numpy as np
    
    # é »å¸¶å®šç¾©
    band_ranges = {
        'low_freq': (20, 500),
        'mid_freq': (500, 2000),
        'mid_high_freq': (2000, 6000),
        'high_freq': (6000, 12000),
        'ultra_high_freq': (12000, 20000)
    }
    
    nyquist = sr / 2
    audio_filtered = np.zeros_like(audio)
    
    # åªä¿ç•™æœªè¢«ç§»é™¤çš„é »å¸¶
    for band_name, (low, high) in band_ranges.items():
        if band_name not in removed_bands:
            low = max(20, low)
            high = min(high, nyquist - 1)
            if low < high:
                try:
                    band_audio = bandpass_filter(audio, sr, low, high)
                    audio_filtered += band_audio
                except:
                    pass
    
    return audio_filtered


def run_band_filter_comparison(audio_original, audio_filtered, sr, removed_bands):
    """é¡¯ç¤ºåŸå§‹èˆ‡éæ¿¾å¾Œçš„é »è­œå°æ¯”"""
    from core.fft import compute_average_spectrum, get_frequency_range
    from core.noise_level import calculate_rms, rms_to_db
    from utils.interactive_plots import create_band_filter_comparison
    
    st.subheader("ğŸšï¸ é »å¸¶éæ¿¾æ•ˆæœå°æ¯”")
    
    band_names = {
        'low_freq': 'ä½é » (é¢¨æ‰‡/é¦¬é”)',
        'mid_freq': 'ä¸­é » (æ©Ÿæ¢°é‹è½‰)',
        'mid_high_freq': 'ä¸­é«˜é » (éµç›¤è²)',
        'high_freq': 'é«˜é » (é›»æ„Ÿå˜¯å«)',
        'ultra_high_freq': 'è¶…é«˜é »'
    }
    
    st.info(f"ğŸ”‡ å·²ç§»é™¤çš„é »å¸¶: {', '.join([band_names.get(b, b) for b in removed_bands])}")
    
    # è¨ˆç®—åŸå§‹å’Œéæ¿¾å¾Œé »è­œ
    freqs_orig, mags_orig = compute_average_spectrum(audio_original, sr)
    freqs_filt, mags_filt = compute_average_spectrum(audio_filtered, sr)
    
    freq_min, freq_max = 20, min(20000, sr // 2)
    freqs_orig, mags_orig = get_frequency_range(freqs_orig, mags_orig, freq_min, freq_max)
    freqs_filt, mags_filt = get_frequency_range(freqs_filt, mags_filt, freq_min, freq_max)
    
    # ç¹ªè£½å°æ¯”åœ–
    filter_fig = create_band_filter_comparison(
        freqs_orig, mags_orig, mags_filt, removed_bands,
        title="åŸå§‹é »è­œ vs éæ¿¾å¾Œé »è­œ"
    )
    st.plotly_chart(filter_fig, use_container_width=True)
    
    # èƒ½é‡è®ŠåŒ–
    col1, col2, col3 = st.columns(3)
    
    rms_orig = calculate_rms(audio_original)
    rms_filt = calculate_rms(audio_filtered)
    db_orig = rms_to_db(rms_orig, 1.0)
    db_filt = rms_to_db(rms_filt, 1.0)
    db_reduction = db_orig - db_filt
    
    with col1:
        st.metric("åŸå§‹èƒ½é‡", f"{db_orig:.1f} dB")
    with col2:
        st.metric("éæ¿¾å¾Œèƒ½é‡", f"{db_filt:.1f} dB")
    with col3:
        st.metric("èƒ½é‡é™ä½", f"{db_reduction:.1f} dB", delta=f"-{db_reduction:.1f}")
    
    st.markdown("---")


if __name__ == "__main__":
    main()



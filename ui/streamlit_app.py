# -*- coding: utf-8 -*-
"""
è²å­¸æ¸¬è©¦åˆ†æç³»çµ± - Streamlit Web UI

åŠŸèƒ½ (AUD-009):
- æª”æ¡ˆä¸Šå‚³ä»‹é¢
- åˆ†æçµæœé¡¯ç¤º
- é »è­œåœ–è¦–è¦ºåŒ–
- å ±å‘Šä¸‹è¼‰
"""

import streamlit as st
import tempfile
import os
from pathlib import Path
import sys
# åŠ å…¥å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from datetime import datetime
from utils.report import generate_excel_report
from utils.pdf_report import generate_pdf_report


def main():
    """Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»å‡½æ•¸"""
    st.set_page_config(
        page_title="è²å­¸æ¸¬è©¦åˆ†æç³»çµ±",
        page_icon="ğŸ”Š",
        layout="wide"
    )
    
    # åˆå§‹åŒ– session_state
    if 'audio_loaded' not in st.session_state:
        st.session_state.audio_loaded = False
    if 'audio_original' not in st.session_state:
        st.session_state.audio_original = None
    if 'sr' not in st.session_state:
        st.session_state.sr = None
    if 'validation' not in st.session_state:
        st.session_state.validation = None

    st.title("ğŸ”Š è²å­¸æ¸¬è©¦åˆ†æç³»çµ±")
    st.markdown("*å°ˆæ¥­ç´šç­†è¨˜å‹é›»è…¦è²å­¸æ¸¬è©¦åˆ†æç³»çµ±*")
    st.markdown("---")

    # å´é‚Šæ¬„è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ åˆ†æè¨­å®š")
        
        # === éº¥å…‹é¢¨æ ¡æº– ===
        with st.expander("ğŸ¤ éº¥å…‹é¢¨æ ¡æº–", expanded=False):
            st.markdown("""
            **æ ¡æº–æ–¹æ³•**ï¼š
            1. ä½¿ç”¨ 94 dB æˆ– 114 dB æ ¡æº–å™¨éŒ„è£½æ ¡æº–éŸ³
            2. æŸ¥çœ‹ç³»çµ±é¡¯ç¤ºçš„ Leq å€¼
            3. è¼¸å…¥åç§»å€¼ = å·²çŸ¥å€¼ - ç³»çµ±é¡¯ç¤ºå€¼
            """)
            calibration_offset = st.number_input(
                "æ ¡æº–åç§» (dB)",
                min_value=-50.0,
                max_value=50.0,
                value=0.0,
                step=0.1,
                help="æ­¤å€¼æœƒåŠ åˆ°æ‰€æœ‰ dB åˆ†æçµæœä¸Šã€‚ä¾‹å¦‚ï¼šæ ¡æº–å™¨ 94 dBï¼Œç³»çµ±é¡¯ç¤º 70 dBï¼Œå‰‡è¼¸å…¥ +24"
            )
            if calibration_offset != 0:
                st.info(f"ğŸ“Œ å·²å¥—ç”¨æ ¡æº–åç§»: **{calibration_offset:+.1f} dB**")
        
        # å°‡æ ¡æº–åç§»å­˜å…¥ session_state
        st.session_state['calibration_offset'] = calibration_offset
        
        # === HEAD ArtemiS å°é½ŠåŠŸèƒ½ ===
        st.subheader("ğŸ“Š é »è­œåˆ†ææ¨¡å¼")
        spectrum_mode = st.selectbox(
            "åˆ†ææ¨¡å¼",
            options=['average', 'peak_hold', 'psd'],
            format_func=lambda x: {
                'average': 'ğŸ“Š FFT Average (å¹³å‡)',
                'peak_hold': 'ğŸ“ˆ FFT Peak Hold (å³°å€¼ä¿æŒ)',
                'psd': 'ğŸ“‰ PSD (åŠŸç‡é »è­œå¯†åº¦)'
            }.get(x, x),
            help="Average: æ™‚é–“å¹³å‡ | Peak Hold: å–æœ€å¤§å€¼ | PSD: åŠŸç‡æ­¸ä¸€åŒ–åˆ° 1 Hz"
        )
        
        window_function = st.selectbox(
            "çª—å‡½æ•¸",
            options=['hann', 'hamming', 'blackman', 'flattop'],
            format_func=lambda x: {
                'hann': 'ğŸ”” Hann (é€šç”¨)',
                'hamming': 'ğŸ”· Hamming (æ›´ä½³æ—ç“£æŠ‘åˆ¶)',
                'blackman': 'âš« Blackman (æœ€ä½³æ—ç“£æŠ‘åˆ¶)',
                'flattop': 'â¬œ Flat Top (å¹…åº¦ç²¾ç¢º)'
            }.get(x, x),
            help="Hann: 95% æ‡‰ç”¨é©ç”¨ | Blackman: éœ€æ¥µä½³æ—ç“£æŠ‘åˆ¶ | Flat Top: å¹…åº¦æ ¡æº–"
        )
        
        # FFT é»æ•¸é¸æ“‡å™¨ (é »ç‡è§£æåº¦æ§åˆ¶)
        n_fft_options = {
            4096: "4096 (æ¨™æº–ï¼Œ~11.7 Hz)",
            8192: "8192 (ç²¾ç´°ï¼Œ~5.9 Hz)",
            16384: "16384 (é«˜ç²¾åº¦ï¼Œ~2.9 Hz)",
            32768: "32768 (è¶…é«˜ç²¾åº¦ï¼Œ~1.5 Hz)"
        }
        n_fft = st.selectbox(
            "FFT é»æ•¸ (é »ç‡è§£æåº¦)",
            options=list(n_fft_options.keys()),
            format_func=lambda x: n_fft_options[x],
            index=1,  # é è¨­ 8192
            help="é»æ•¸è¶Šé«˜ï¼Œé »ç‡è§£æåº¦è¶Šç²¾ç¢ºï¼Œä½†è¨ˆç®—æ™‚é–“è¶Šé•·"
        )
        
        # é¡¯ç¤ºå¯¦éš›é »ç‡è§£æåº¦
        freq_resolution = 48000 / n_fft  # å‡è¨­ 48kHz å–æ¨£ç‡
        st.caption(f"ğŸ“ é »ç‡è§£æåº¦: **{freq_resolution:.2f} Hz**")
        
        highpass_cutoff = st.slider(
            "é«˜é€šæ¿¾æ³¢æˆªæ­¢é »ç‡ (Hz)",
            min_value=20, max_value=8000, value=20, step=10,
            help="æ¿¾é™¤ä½æ–¼æ­¤é »ç‡çš„è²éŸ³ã€‚20 Hz = äººè€³ä¸‹é™ï¼ˆä¿ç•™å®Œæ•´é »è­œï¼‰ã€‚ç•¶ã€Œé »å¸¶éæ¿¾æ¨¡æ“¬ã€é–‹å•Ÿæ™‚ï¼Œæ­¤è¨­å®šæœƒè¢«å¿½ç•¥ã€‚"
        )
        
        st.markdown("---")
        
        st.subheader("ğŸ“‹ åˆ†æé¸é …")
        analyze_noise = st.checkbox("å™ªéŸ³ç­‰ç´šåˆ†æ dB(A)", value=True)
        
        leq_settings = {'spec': None, 'tag': ''}
        if analyze_noise:
            col_tag, col_spec = st.columns([1, 1])
            with col_tag:
                leq_tag = st.text_input(
                    "æ¸¬è©¦æ¨™ç±¤ (é¸å¡«)",
                    placeholder="ä¾‹å¦‚: IDLE",
                    help="æ¸¬è©¦æƒ…å¢ƒæ¨™ç±¤ï¼Œå°‡é¡¯ç¤ºæ–¼å ±å‘Šä¸­"
                )
            with col_spec:
                leq_spec_val = st.number_input(
                    "Leq æ¨™æº– (dB)",
                    min_value=0.0,
                    max_value=120.0,
                    value=0.0,
                    step=1.0,
                    help="è‹¥æ¸¬é‡ > æ¨™æº–å‰‡é¡¯ç¤º FAIL"
                )
            
            if leq_spec_val > 0:
                leq_settings['spec'] = leq_spec_val
                leq_settings['tag'] = leq_tag if leq_tag else "Noise Check"
        analyze_spectrum = st.checkbox("FFT é »è­œåˆ†æ", value=True)
        
        if analyze_spectrum:
            # Level vs Time å¹³æ»‘è¨­å®š
            smooth_window_size = st.number_input(
                "ğŸŒŠ Level vs Time å¹³æ»‘åº¦ (Smoothing)",
                min_value=1,
                value=1,
                step=1,
                help="è¨­å®š Level vs Time åœ–è¡¨çš„ç§»å‹•å¹³å‡çª—å£å¤§å°ã€‚1 ç‚ºåŸå§‹æ•¸æ“š (æœ€éˆæ•)ï¼Œæ•¸å€¼è¶Šå¤§è¶Šå¹³æ»‘ã€‚"
            )
            st.caption(f"ç›®å‰è¨­å®š: {'åŸå§‹æ•¸æ“š (Fast)' if smooth_window_size == 1 else f'å¹³æ»‘è¦–çª— {smooth_window_size} frames'}")
        else:
            smooth_window_size = 1 # Default if hidden
        
        # A-weighting é¸é … (é è¨­å•Ÿç”¨)
        use_a_weighting = st.checkbox(
            "ğŸ‘‚ å¥—ç”¨ A-weighting åŠ æ¬Š", 
            value=True,
            help="A-weighting æ¨¡æ“¬äººè€³å°ä¸åŒé »ç‡çš„æ•æ„Ÿåº¦ï¼Œç¬¦åˆ IEC 61672-1 æ¨™æº–"
        )
        
        # Spectrogram é¡¯ç¤ºæ¨¡å¼
        st.markdown("##### ğŸ¨ Spectrogram è¨­å®š")
        

        
        # dB SPL çµ•å°æ¨¡å¼
        spectrogram_use_spl = st.checkbox(
            "ğŸ“Š dB SPL çµ•å°æ¨¡å¼",
            value=False,
            help="å•Ÿç”¨å¾Œé¡¯ç¤ºçµ•å° dB SPL å€¼ï¼ˆéœ€è¦æ ¡æº–åç§»ï¼‰ã€‚é è¨­ä½¿ç”¨ç›¸å°åŠŸç‡ dBã€‚"
        )
        
        # Spectrogram æ ¡æº–åç§»ï¼ˆåªåœ¨ dB SPL æ¨¡å¼ä¸‹é¡¯ç¤ºï¼‰
        if spectrogram_use_spl:
            spectrogram_spl_offset = st.number_input(
                "Spectrogram æ ¡æº–åç§» (dB)",
                value=0.0,
                step=10.0,
                help="å°‡ç›¸å° dB è½‰æ›ç‚º dB SPL æ‰€éœ€çš„åç§»é‡ã€‚å¯å¾ HEAD acoustics å°æ¯”ç²å¾—ã€‚"
            )
            st.info("ğŸ’¡ å°æ¯” HEAD acoustics çš„ç›¸åŒéŸ³è¨Šä¾†ç¢ºå®šåç§»å€¼")
        else:
            spectrogram_spl_offset = 0.0
        
        # Spectrogram è‰²å½©ç¯„åœæ§åˆ¶
        spectrogram_auto_range = st.checkbox(
            "ğŸ”„ è‡ªå‹•ç¯„åœ",
            value=True,
            help="è‡ªå‹•èª¿æ•´ Spectrogram è‰²å½©ç¯„åœã€‚é—œé–‰å¾Œå¯æ‰‹å‹•è¨­å®šã€‚"
        )
        
        if spectrogram_auto_range:
            spectrogram_z_range = None
        else:
            spec_col1, spec_col2 = st.columns(2)
            with spec_col1:
                spec_z_min = st.number_input("æœ€å°å€¼ (dB)", value=-100, step=10)
            with spec_col2:
                spec_z_max = st.number_input("æœ€å¤§å€¼ (dB)", value=-60, step=10)
            spectrogram_z_range = (spec_z_min, spec_z_max)
        
        analyze_discrete_tone = st.checkbox("Discrete Tone æª¢æ¸¬", value=True)
        
        # ECMA æ¨™æº–é¸æ“‡
        ecma_standard = 'ECMA-74'
        if analyze_discrete_tone:
            ecma_standard = st.radio(
                "Discrete Tone åˆ¤å®šæ¨™æº–",
                options=['ECMA-74', 'ECMA-418'],
                index=0,  # é è¨­ ECMA-74
                horizontal=True,
                help="ECMA-74: å›ºå®šé »å¸¶é–€æª» (è¼ƒå¯¬é¬†) | ECMA-418: å…¬å¼è¨ˆç®—é–€æª» (è¼ƒåš´æ ¼)"
            )
        
        analyze_sop = st.checkbox("ASUS SOW é«˜é »åˆ†æ", value=True)
        
        # SOP åƒæ•¸ï¼šæ”¯æ´å¤šæ¨¡å¼é¸æ“‡
        sop_params = {'modes': []}
        if analyze_sop:
            st.caption("é¸æ“‡è¦åˆ†æçš„ SOP æ¨¡å¼ï¼ˆå¯è¤‡é¸ï¼‰")
            
            # IDLE æ¨¡å¼
            sop_idle = st.checkbox("ğŸ”‡ IDLE æ¨¡å¼", value=False, key="sop_idle")
            if sop_idle:
                sop_params['modes'].append('IDLE')
                sop_params['idle_spec'] = st.number_input(
                    "IDLE SPEC ç®¡åˆ¶ç·š (dBA)", value=22.0, step=0.5, key="idle_spec"
                )
            
            # UE æ¨¡å¼
            sop_ue = st.checkbox("ğŸ‘¤ UE æ¨¡å¼", value=False, key="sop_ue")
            if sop_ue:
                sop_params['modes'].append('UE')
                sop_params['ue_spec'] = st.number_input(
                    "UE SPEC ç®¡åˆ¶ç·š (dBA)", value=22.0, step=0.5, key="ue_spec"
                )
            
            # Workload æ¨¡å¼
            sop_workload = st.checkbox("âš¡ Workload æ¨¡å¼", value=True, key="sop_workload")
            if sop_workload:
                sop_params['modes'].append('Workload')
                sop_params['work_spec_fail'] = st.number_input(
                    "Fail Rate SPEC (dBA)", value=22.0, step=0.5, key="work_spec_fail"
                )
                sop_params['work_spec_max'] = st.number_input(
                    "Max Leq SPEC (dBA)", value=28.0, step=0.5, key="work_spec_max"
                )
            
            # å‘å¾Œå…¼å®¹ï¼šè¨­å®š mode ç‚ºç¬¬ä¸€å€‹é¸æ“‡çš„æ¨¡å¼
            if sop_params['modes']:
                sop_params['mode'] = sop_params['modes'][0]
        
        analyze_band_filter = st.checkbox("ğŸšï¸ é »å¸¶éæ¿¾æ¨¡æ“¬", value=False)
        
        # é »å¸¶é¸æ“‡å™¨
        removed_bands = []
        if analyze_band_filter:
            st.markdown("---")
            st.subheader("ğŸšï¸ é »å¸¶éæ¿¾æ¨¡æ“¬")
            st.caption("é¸æ“‡è¦ç§»é™¤çš„é »å¸¶ï¼Œæ¨¡æ“¬å»é™¤ç‰¹å®šå™ªéŸ³ä¾†æºçš„æ•ˆæœ")
            
            remove_low = st.checkbox("ç§»é™¤ä½é » (20-500Hz) - é¢¨æ‰‡/é¦¬é”", value=False, key="rm_low")
            remove_mid = st.checkbox("ç§»é™¤ä¸­é » (500-2kHz) - æ©Ÿæ¢°é‹è½‰", value=False, key="rm_mid")
            remove_mid_high = st.checkbox("ç§»é™¤ä¸­é«˜é » (2-6kHz) - éµç›¤è²", value=False, key="rm_mid_high")
            remove_high = st.checkbox("ç§»é™¤é«˜é » (6-12kHz) - é›»æ„Ÿå˜¯å«", value=False, key="rm_high")
            remove_ultra = st.checkbox("ç§»é™¤è¶…é«˜é » (12-20kHz)", value=False, key="rm_ultra")
            
            if remove_low:
                removed_bands.append("low_freq")
            if remove_mid:
                removed_bands.append("mid_freq")
            if remove_mid_high:
                removed_bands.append("mid_high_freq")
            if remove_high:
                removed_bands.append("high_freq")
            if remove_ultra:
                removed_bands.append("ultra_high_freq")
        
        st.markdown("---")
        st.subheader("ğŸ“„ å ±å‘Šç”Ÿæˆ")
        
        if st.session_state.get('audio_loaded', False):
            # Excel å ±å‘Š
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ“Š Excel å ±å‘Š", key="btn_gen_excel", use_container_width=True):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆ Excel å ±å‘Š..."):
                        # ç²å–æ ¡æº–åç§»
                        excel_cal_offset = st.session_state.get('calibration_offset', 0.0)
                        
                        # æ§‹å»ºå®Œæ•´çš„åˆ†æè¨­å®š
                        analysis_settings = {
                            'use_a_weighting': use_a_weighting,
                            'spectrum_mode': spectrum_mode,
                            'window_function': window_function,
                            'n_fft': n_fft,
                            'ecma_standard': ecma_standard,
                            'spectrogram_spl_offset': spectrogram_spl_offset,
                            'highpass_cutoff': highpass_cutoff
                        }
                        
                        report_data, error = generate_excel_report(
                            st.session_state.audio_original,
                            st.session_state.sr,
                            filename=st.session_state.get('audio_filename', "audio.wav"),
                            sop_params=sop_params,
                            calibration_offset=excel_cal_offset,
                            analysis_settings=analysis_settings
                        )
                        
                        if error:
                            st.error(error)
                        else:
                            st.session_state['report_xlsx'] = report_data
                            st.success("âœ… Excel å ±å‘Šå·²ç”Ÿæˆ")

                if 'report_xlsx' in st.session_state:
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è¼‰ Excel",
                        data=st.session_state['report_xlsx'],
                        file_name=f"Report_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
            
            with col2:
                if st.button("ğŸ“‘ PDF å ±å‘Š", key="btn_gen_pdf", use_container_width=True):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆ PDF å ±å‘Šï¼ˆå«åœ–è¡¨ï¼‰..."):
                        # å¼·åˆ¶é‡æ–°è¼‰å…¥ pdf_report æ¨¡çµ„ï¼Œç¢ºä¿ä½¿ç”¨æœ€æ–°ä»£ç¢¼
                        import importlib
                        import utils.pdf_report as pdf_report_module
                        importlib.reload(pdf_report_module)
                        
                        pdf_data, error = pdf_report_module.generate_pdf_report(
                            st.session_state.audio_original,
                            st.session_state.sr,
                            filename=st.session_state.get('audio_filename', "audio.wav"),
                            sop_params=sop_params if analyze_sop else None,
                            analyze_discrete_tone_flag=analyze_discrete_tone,
                            calibration_offset=calibration_offset,
                            leq_settings=leq_settings,
                            use_a_weighting=use_a_weighting,
                            spectrum_mode=spectrum_mode,
                            window_function=window_function,
                            n_fft=n_fft,
                            fft_chart=st.session_state.get('fft_chart_figure', None),
                            level_time_chart=st.session_state.get('level_time_chart_figure', None),
                            octave_chart=st.session_state.get('octave_chart_figure', None),
                            ecma_standard=ecma_standard
                        )
                        
                        if error:
                            st.error(f"PDF ç”Ÿæˆå¤±æ•—: {error}")
                        else:
                            st.session_state['report_pdf'] = pdf_data
                            st.success("âœ… PDF å ±å‘Šå·²ç”Ÿæˆ")

                if 'report_pdf' in st.session_state:
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è¼‰ PDF",
                        data=st.session_state['report_pdf'],
                        file_name=f"Report_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                        mime="application/pdf",
                        use_container_width=True
                    )
        else:
            st.caption("è«‹å…ˆä¸Šå‚³éŸ³æª”ä»¥å•Ÿç”¨å ±å‘ŠåŠŸèƒ½")

        st.markdown("---")
        st.caption("v1.0.0 | è²å­¸æ¸¬è©¦ AI åˆ†æç³»çµ±")

    # ä¸»è¦å…§å®¹å€
    st.header("ğŸ“ ä¸Šå‚³éŸ³æª”")
    
    uploaded_files = st.file_uploader(
        "é¸æ“‡è¦åˆ†æçš„éŸ³æª” (æ”¯æ´å¤šé¸)",
        type=["wav", "mp3", "flac"],
        accept_multiple_files=True,
        help="æ”¯æ´ WAVã€MP3ã€FLAC æ ¼å¼ï¼Œæª”æ¡ˆå¤§å°ä¸Šé™ 50MB"
    )

    if uploaded_files:
        if len(uploaded_files) == 1:
            uploaded_file = uploaded_files[0]
            st.success(f"âœ… å·²ä¸Šå‚³: **{uploaded_file.name}** ({uploaded_file.size / 1024 / 1024:.2f} MB)")
            
            # é–‹å§‹åˆ†ææŒ‰éˆ• - åªè¼‰å…¥éŸ³æª”ä¸€æ¬¡
            if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True):
                load_audio_file(uploaded_file)
            
            # å¦‚æœéŸ³æª”å·²è¼‰å…¥ï¼Œæ ¹æ“šå´é‚Šæ¬„è¨­å®šå³æ™‚é¡¯ç¤ºåˆ†æçµæœ
            if st.session_state.audio_loaded:
                # ä½¿ç”¨ streamlit components åŸ·è¡Œ JavaScript æ»¾å‹•åˆ°é ‚éƒ¨
                import streamlit.components.v1 as components
                components.html("""
                    <script>
                        // æ»¾å‹•åˆ°é é¢é ‚éƒ¨
                        window.parent.document.querySelector('section.main').scrollTo({
                            top: 0,
                            behavior: 'smooth'
                        });
                    </script>
                """, height=0)
                
                # Streamlit åŸç”Ÿçš„ spinner æœƒåœ¨å³ä¸Šè§’é¡¯ç¤º "Running..."
                with st.spinner("ğŸ”„ åˆ†æä¸­ï¼Œè«‹ç¨å€™..."):
                    render_analysis_results(
                        highpass_cutoff,
                        analyze_noise,
                        analyze_spectrum,
                        analyze_discrete_tone,
                        analyze_sop,
                        sop_params,
                        analyze_band_filter,
                        removed_bands,
                        use_a_weighting,
                        spectrum_mode,
                        window_function,
                        n_fft,
                        ecma_standard,
                        spectrogram_z_range,
                        spectrogram_spl_offset,
                        leq_settings,
                        smooth_window_size
                    )
        else:
            # æ‰¹æ¬¡æ¨¡å¼
            st.success(f"âœ… å·²ä¸Šå‚³ **{len(uploaded_files)}** å€‹æª”æ¡ˆï¼Œæº–å‚™é€²è¡Œæ‰¹æ¬¡åˆ†æ")
            if st.button(f"ğŸš€ é–‹å§‹æ‰¹æ¬¡åˆ†æ", type="primary", use_container_width=True):
                process_batch_analysis(uploaded_files, analyze_sop, sop_params)
            
            if st.session_state.get('batch_data'):
                render_batch_dashboard(
                    highpass_cutoff,
                    analyze_noise,
                    analyze_spectrum,
                    analyze_discrete_tone,
                    analyze_sop,
                    sop_params,
                    False,  # analyze_high_freq (deprecated)
                    analyze_band_filter,
                    removed_bands,
                    use_a_weighting,
                    spectrum_mode,
                    window_function,
                    n_fft,
                    smooth_window_size
                )
    else:
        # æ¸…é™¤å·²è¼‰å…¥çš„éŸ³æª”
        st.session_state.audio_loaded = False
        st.session_state.audio_original = None
        
        st.info("ğŸ‘† è«‹ä¸Šå‚³éŸ³æª”ä»¥é–‹å§‹åˆ†æ")
        
        # é¡¯ç¤ºæ”¯æ´çš„è¦æ ¼
        with st.expander("ğŸ“Œ æ”¯æ´çš„éŸ³æª”è¦æ ¼"):
            st.markdown("""
            | é …ç›® | è¦æ ¼ |
            |------|------|
            | æ ¼å¼ | WAV (å¿…é ˆ), MP3, FLAC (å¯é¸) |
            | å–æ¨£ç‡ | 44100 æˆ– 48000 Hz |
            | ä½å…ƒæ·±åº¦ | 16-bit æˆ– 24-bit |
            | è²é“ | Mono (å–®è²é“) |
            | æª”æ¡ˆå¤§å° | â‰¤ 50 MB |
            | é•·åº¦ | 10 - 120 ç§’ |
            """)


def load_audio_file(uploaded_file):
    """è¼‰å…¥éŸ³æª”åˆ° session_state"""
    with st.spinner("ğŸ”„ æ­£åœ¨è¼‰å…¥ä¸¦é©—è­‰éŸ³æª”..."):
        from core.audio_loader import load_audio, validate_audio
        
        # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(
            suffix=f".{uploaded_file.name.split('.')[-1]}",
            delete=False
        ) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        try:
            # é©—è­‰éŸ³æª”
            validation = validate_audio(tmp_path, strict=False)
            
            if not validation["file_valid"]:
                st.error(f"âŒ éŸ³æª”é©—è­‰å¤±æ•—: {validation['error_message']}")
                return
            
            # è¼‰å…¥éŸ³æª”
            audio, sr = load_audio(tmp_path)
            
            # ä¿å­˜åˆ° session_state
            st.session_state.audio_original = audio
            st.session_state.sr = sr
            st.session_state.validation = validation
            st.session_state.audio_loaded = True
            st.session_state.audio_filename = uploaded_file.name
            
            st.rerun()  # é‡æ–°é‹è¡Œä»¥é¡¯ç¤ºåˆ†æçµæœ
            
        finally:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            os.unlink(tmp_path)


def get_band_frequencies(band_keys):
    """å°‡é »å¸¶ Key è½‰æ›ç‚ºå¯¦éš›çš„ 1/3 Octave ä¸­å¿ƒé »ç‡åˆ—è¡¨"""
    frequencies = []
    mapping = {
        'low_freq': [20, 25, 31.5, 40, 50, 63, 80, 100, 125, 160, 200, 250, 315, 400],
        'mid_freq': [500, 630, 800, 1000, 1250, 1600, 2000],
        'mid_high_freq': [2500, 3150, 4000, 5000],
        'high_freq': [6300, 8000, 10000, 12500],
        'ultra_high_freq': [16000, 20000]
    }
    for key in band_keys:
        frequencies.extend(mapping.get(key, []))
    return frequencies


def render_analysis_results(highpass_cutoff, analyze_noise, analyze_spectrum, 
                            analyze_discrete_tone, analyze_sop, sop_params,
                            analyze_band_filter, removed_bands, use_a_weighting=True,
                            spectrum_mode='average', window_function='hann', n_fft=8192,
                            ecma_standard='ECMA-74', spectrogram_z_range=None,
                            spectrogram_spl_offset=0.0, leq_settings=None,
                            smooth_window_size=1):
    """æ ¹æ“šå´é‚Šæ¬„è¨­å®šå³æ™‚æ¸²æŸ“åˆ†æçµæœ
    
    Args:
        highpass_cutoff: é«˜é€šæ¿¾æ³¢æˆªæ­¢é »ç‡
        analyze_noise: æ˜¯å¦åˆ†æå™ªéŸ³ç­‰ç´š
        analyze_spectrum: æ˜¯å¦åˆ†æé »è­œ
        analyze_discrete_tone: æ˜¯å¦æª¢æ¸¬ Discrete Tone
        analyze_high_freq: æ˜¯å¦åˆ†æé«˜é »
        analyze_band_filter: æ˜¯å¦å•Ÿç”¨é »å¸¶éæ¿¾
        removed_bands: è¦ç§»é™¤çš„é »å¸¶åˆ—è¡¨
        use_a_weighting: æ˜¯å¦å¥—ç”¨ A-weighting
        spectrum_mode: é »è­œåˆ†ææ¨¡å¼ (average/peak_hold/psd)
        window_function: çª—å‡½æ•¸é¡å‹
        n_fft: FFT é»æ•¸
        ecma_standard: ECMA æ¨™æº–ç‰ˆæœ¬
        spectrogram_z_range: Spectrogram é¡¯ç¤ºç¯„åœ
        spectrogram_spl_offset: Spectrogram SPL åç§»
        leq_settings: Leq åˆ¤å®šè¨­å®š (spec/tag)
        smooth_window_size: Level vs Time å¹³æ»‘è¦–çª—å¤§å°
    """
    # ç¢ºä¿ session_state ä¸­æœ‰éŸ³æª”è³‡æ–™
    if not st.session_state.audio_loaded:
        st.warning("âš ï¸ è«‹å…ˆä¸Šå‚³ä¸¦è¼‰å…¥éŸ³è¨Šæª”æ¡ˆã€‚")
        return

    # å¾ session_state ç²å–åŸå§‹éŸ³è¨Š
    audio_original = st.session_state.audio_original
    sr = st.session_state.sr
    validation = st.session_state.validation
    
    # === éŸ³è¨Šå‰è™•ç† (éæ¿¾) ===
    audio_processed = audio_original  # åˆå§‹ç‚ºåŸå§‹éŸ³è¨Š (ä¸è¦ä¿®æ”¹åŸå§‹è³‡æ–™)
    
    # 1. æ‡‰ç”¨å¸¶é˜»æ¿¾æ³¢å™¨ (é »å¸¶éæ¿¾æ¨¡æ“¬)
    if analyze_band_filter and removed_bands:
        from core.band_analyzer import apply_band_rejection
        target_frequencies = get_band_frequencies(removed_bands)
        audio_processed = apply_band_rejection(audio_processed, sr, target_frequencies)
        st.warning(f"âš ï¸ **é »å¸¶éæ¿¾å•Ÿç”¨**: å·²ç§»é™¤ {len(target_frequencies)} å€‹ 1/3 å€é »ç¨‹é »å¸¶ (é¸æ“‡äº† {len(removed_bands)} å€‹å€åŸŸ)ã€‚åˆ†æçµæœåŸºæ–¼éæ¿¾å¾Œçš„éŸ³è¨Šã€‚")
    
    # 2. æ‡‰ç”¨é«˜é€šæ¿¾æ³¢ (å…¨åŸŸè¨­å®šï¼Œé è¨­é€šå¸¸å»ºè­° 20Hz)
    # é‚è¼¯ä¿®æ­£ï¼šç•¶ã€Œé »å¸¶éæ¿¾æ¨¡æ“¬ã€å•Ÿç”¨æ™‚ï¼Œå¿½ç•¥æ­¤è¨­å®šï¼Œé¿å…é›™é‡æ¿¾æ³¢é€ æˆæ··æ·†
    is_band_filter_active = analyze_band_filter and removed_bands
    
    if highpass_cutoff > 0 and not is_band_filter_active:
        from scipy.signal import butter, sosfiltfilt
        sos = butter(4, highpass_cutoff, 'hp', fs=sr, output='sos')
        audio_processed = sosfiltfilt(sos, audio_processed)
        
        # ç•¶é »ç‡è¼ƒé«˜æ™‚é¡¯ç¤ºè³‡è¨Š
        if highpass_cutoff > 20: 
            st.info(f"ğŸ”Š **é«˜é€šæ¿¾æ³¢å·²å•Ÿç”¨**: æˆªæ­¢é »ç‡ {highpass_cutoff} Hz")
    elif highpass_cutoff > 20 and is_band_filter_active:
        st.caption(f"â„¹ï¸ é«˜é€šæ¿¾æ³¢è¨­å®š ({highpass_cutoff} Hz) å·²æš«æ™‚å¿½ç•¥ï¼Œå› ç‚ºé »å¸¶éæ¿¾æ¨¡æ“¬æ­£åœ¨é‹ä½œä¸­ã€‚")

    
    # é¡¯ç¤ºåŠ æ¬Šæ¨¡å¼
    pass
    
    # é¡¯ç¤ºéŸ³æª”è³‡è¨Š
    display_audio_info(validation)
    
    # === åŒæ­¥éŸ³è¨Šæ’­æ”¾å™¨ (å¸¶ Spectrogram é€²åº¦ç·š) ===
    from ui.audio_player import create_audio_player_with_spectrogram, create_simple_audio_player
    
    # ç²å–æ ¡æº–åç§»
    player_cal_offset = st.session_state.get('calibration_offset', 0.0)
    
    # ç²å– SPL åç§»ï¼ˆå¦‚æœå•Ÿç”¨ dB SPL æ¨¡å¼ï¼‰
    player_spl_offset = spectrogram_spl_offset
    
    if analyze_band_filter and removed_bands:
        # æœ‰é »å¸¶éæ¿¾æ™‚é¡¯ç¤ºå…©å€‹æ’­æ”¾å™¨
        col1, col2 = st.columns(2)
        with col1:
            st.caption("ğŸ§ **éæ¿¾å¾ŒéŸ³è¨Š** (åŸºæ–¼æ­¤é€²è¡Œåˆ†æ)")
            create_audio_player_with_spectrogram(audio_processed, sr, "ğŸµ éæ¿¾å¾ŒéŸ³è¨Šæ’­æ”¾å™¨", 
                                                  calibration_offset=player_cal_offset,
                                                  use_a_weighting=use_a_weighting,
                                                  spl_offset=player_spl_offset)
        with col2:
            st.caption("ğŸ”Š **åŸå§‹éŸ³è¨Š** (å°ç…§åƒè€ƒ)")
            create_audio_player_with_spectrogram(audio_original, sr, "ğŸ”Š åŸå§‹éŸ³è¨Šæ’­æ”¾å™¨", 
                                                  calibration_offset=player_cal_offset,
                                                  use_a_weighting=use_a_weighting,
                                                  spl_offset=player_spl_offset)
    else:
        # åªé¡¯ç¤ºä¸€å€‹æ’­æ”¾å™¨
        create_audio_player_with_spectrogram(audio_processed, sr, "ğŸµ éŸ³è¨Šæ’­æ”¾å™¨ (é»æ“Šé »è­œåœ–å¯è·³è½‰)", 
                                              calibration_offset=player_cal_offset,
                                              use_a_weighting=use_a_weighting,
                                              spl_offset=player_spl_offset)
    
    st.markdown("---")
    
    # åŸ·è¡Œå„é …åˆ†æ (ä½¿ç”¨éæ¿¾å¾Œçš„éŸ³è¨Šï¼Œå‚³å…¥ A-weighting è¨­å®š)
    if analyze_noise:
        run_noise_analysis(audio_processed, sr, use_a_weighting, leq_settings)

    # ç”¢ç”Ÿå”¯ä¸€çš„ Key Suffixï¼Œç¢ºä¿éæ¿¾å™¨åƒæ•¸è®Šæ›´æ™‚åœ–è¡¨æœƒå¼·åˆ¶é‡ç¹ª
    filter_key_suffix = f"{str(removed_bands)}" if analyze_band_filter and removed_bands else "raw"

    if analyze_spectrum:
        run_spectrum_analysis(
            audio_processed, sr, use_a_weighting, spectrum_mode, window_function, n_fft, 
            spectrogram_z_range, spectrogram_spl_offset=spectrogram_spl_offset, 
            smooth_window=smooth_window_size,
            highpass_cutoff=highpass_cutoff,
            calibration_offset=st.session_state.get('calibration_offset', 0.0),
            key_suffix=filter_key_suffix
        )

    if analyze_discrete_tone:
        run_discrete_tone_analysis(
            audio_processed, sr, spectrum_mode, window_function, n_fft, use_a_weighting, 
            ecma_standard, highpass_cutoff=highpass_cutoff,
            key_suffix=filter_key_suffix,
            removed_bands_keys=removed_bands if analyze_band_filter else None
        )

    if analyze_sop:
        run_sop_analysis(audio_processed, sr, sop_params)

    # å¦‚æœæœ‰é »å¸¶éæ¿¾ï¼Œé¡¯ç¤ºåŸå§‹ vs éæ¿¾å¾Œå°æ¯”
    if analyze_band_filter and removed_bands:
        run_band_filter_comparison(audio_original, audio_processed, sr, removed_bands)

    st.success("âœ… åˆ†æå®Œæˆï¼å´é‚Šæ¬„èª¿æ•´è¨­å®šæœƒå³æ™‚æ›´æ–°åœ–è¡¨ã€‚")



def display_audio_info(validation: dict):
    """é¡¯ç¤ºéŸ³æª”è³‡è¨Š"""
    st.subheader("ğŸ“Š éŸ³æª”è³‡è¨Š")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("å–æ¨£ç‡", f"{validation['sample_rate']} Hz")
    with col2:
        st.metric("é•·åº¦", f"{validation['duration']:.2f} ç§’")
    with col3:
        st.metric("ä½å…ƒæ·±åº¦", f"{validation['bit_depth']}-bit")
    with col4:
        st.metric("æª”æ¡ˆå¤§å°", f"{validation['file_size_mb']:.2f} MB")
    
    if validation.get("warnings"):
        for warning in validation["warnings"]:
            st.warning(f"âš ï¸ {warning}")


def run_noise_analysis(audio, sr, use_a_weighting=True, leq_settings=None):
    """åŸ·è¡Œå™ªéŸ³ç­‰ç´šåˆ†æ"""
    from core.noise_level import calculate_noise_level
    
    result = calculate_noise_level(audio, sr, apply_weighting=use_a_weighting)
    
    # å–å¾—æ ¡æº–åç§»
    cal_offset = st.session_state.get('calibration_offset', 0.0)
    
    # å¥—ç”¨æ ¡æº–åç§»
    leq = result['leq_dba'] + cal_offset
    lmax = result['lmax_dba'] + cal_offset
    lmin = result['lmin_dba'] + cal_offset
    l10 = result['l10'] + cal_offset
    l90 = result['l90'] + cal_offset
    
    # å‹•æ…‹å–®ä½æ¨™ç±¤
    unit_label = "dB(A)" if use_a_weighting else "dB"
    
    st.subheader(f"ğŸ”Š å™ªéŸ³ç­‰ç´šåˆ†æ {unit_label}")
    
    # é¡¯ç¤ºæ ¡æº–ç‹€æ…‹
    if cal_offset != 0:
        st.caption(f"ğŸ“Œ å·²å¥—ç”¨æ ¡æº–åç§»: **{cal_offset:+.1f} dB**")
    
    # å®šç¾©è³‡è¨Šå¡ç‰‡å‡½æ•¸
    def card(label, value, unit, description, is_primary=False, is_fail=False):
        if is_fail:
            border_color = "#E74C3C"  # ç´…è‰²é‚Šæ¡†
            bg_color = "#FDEDEC"      # æ·ºç´…èƒŒæ™¯
            text_color = "#C0392B"    # æ·±ç´…æ–‡å­—
            box_shadow = "0 4px 6px rgba(231, 76, 60, 0.2)"
        elif is_primary:
            border_color = "#4A90E2"
            bg_color = "#F0F7FF"
            text_color = "#2c3e50"
            box_shadow = "0 4px 6px rgba(0,0,0,0.1)"
        else:
            border_color = "#E0E0E0"
            bg_color = "#FFFFFF"
            text_color = "#2c3e50"
            box_shadow = "0 1px 3px rgba(0,0,0,0.05)"
        
        return f"""
        <div style="
            border: 2px solid {border_color};
            border-radius: 10px;
            padding: 15px 10px;
            text-align: center;
            background-color: {bg_color};
            box-shadow: {box_shadow};
            height: 100%;
            display: flex;
            flex-direction: column;
            justify_content: center;
            align_items: center;
        ">
            <div style="font-size: 14px; color: #888; font-weight: bold; margin-bottom: 5px;">{label}</div>
            <div style="font-size: 28px; font-weight: bold; color: {text_color}; margin: 5px 0;">{value}</div>
            <div style="font-size: 12px; color: #666; background: rgba(0,0,0,0.05); padding: 2px 8px; border-radius: 10px; display: inline-block;">{unit}</div>
            <div style="font-size: 11px; color: #999; margin-top: 8px;">{description}</div>
        </div>
        """

    # åˆ¤å®š Leq æ˜¯å¦è¶…æ¨™
    leq_fail = False
    
    # è§£æè¨­å®š
    leq_spec = None
    leq_tag = ""
    if leq_settings and leq_settings.get('spec'):
        leq_spec = leq_settings.get('spec')
        leq_tag = leq_settings.get('tag', '')

    leq_desc_line1 = "ç­‰æ•ˆé€£çºŒéŸ³å£“ (å¹³å‡)"
    if leq_tag:
        leq_desc_line1 = f"<b>{leq_tag}</b>"
        
    leq_desc = leq_desc_line1
    if leq_spec is not None:
        if leq > leq_spec:
            leq_fail = True
            leq_desc += f"<br>âš ï¸ è¶…æ¨™ ({leq_spec} dB)"
        else:
            leq_desc += f"<br>âœ… åˆæ ¼ ({leq_spec} dB)"

    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown(card("Leq", f"{leq:.1f}", unit_label, leq_desc, is_primary=True, is_fail=leq_fail), unsafe_allow_html=True)
    with col2:
        st.markdown(card("Lmax", f"{lmax:.1f}", unit_label, "æœ€å¤§éŸ³å£“ç´š"), unsafe_allow_html=True)
    with col3:
        st.markdown(card("Lmin", f"{lmin:.1f}", unit_label, "èƒŒæ™¯å™ªéŸ³åƒè€ƒ"), unsafe_allow_html=True)
    with col4:
        st.markdown(card("L10", f"{l10:.1f}", unit_label, "å³°å€¼å™ªéŸ³ (10%)"), unsafe_allow_html=True)
    with col5:
        st.markdown(card("L90", f"{l90:.1f}", unit_label, "èƒŒæ™¯æŒçºŒ (90%)"), unsafe_allow_html=True)
    
    st.markdown("---")


def run_spectrum_analysis(audio, sr, use_a_weighting=True, 
                          spectrum_mode='average', window_function='hann', n_fft=8192,
                          spectrogram_z_range=None, calibration_offset=0.0,
                          spectrogram_spl_offset=0.0, smooth_window=1,
                          highpass_cutoff=0, key_suffix=""):
    """åŸ·è¡Œé »è­œåˆ†æ - å¤šç¨®åœ–è¡¨å³æ™‚åˆ‡æ›
    
    Args:
        audio: éŸ³è¨Šè³‡æ–™
        sr: å–æ¨£ç‡
        use_a_weighting: æ˜¯å¦å¥—ç”¨ A-weighting åŠ æ¬Š
        spectrum_mode: åˆ†ææ¨¡å¼ (average/peak_hold/psd)
        window_function: çª—å‡½æ•¸ (hann/hamming/blackman/flattop)
        n_fft: FFT é»æ•¸ (æ±ºå®šé »ç‡è§£æåº¦)
        spectrogram_z_range: Spectrogram è‰²å½©ç¯„åœ (z_min, z_max)
        calibration_offset: æ ¡æº–åç§» (dB)
        spectrogram_spl_offset: Spectrogram dB SPL åç§» (dB)
        smooth_window: Level vs Time å¹³æ»‘è¦–çª—å¤§å°
    """
    from core.fft import compute_spectrum_with_mode, apply_a_weighting
    from core.noise_level import calculate_noise_level
    from utils.interactive_plots import (
        create_interactive_spectrum,
        create_waveform_chart,
        create_spectrogram_chart,
        create_a_weighting_chart,
        create_octave_band_chart,
        create_waterfall_3d_chart,
        create_combined_analysis_chart,
        create_level_vs_time_chart,
        create_spectrum_with_leq_line
    )
    import numpy as np
    
    # åˆ†ææ¨¡å¼å°æ‡‰çš„æ¨™ç±¤
    mode_labels = {
        'average': 'FFT Average',
        'peak_hold': 'FFT Peak Hold',
        'psd': 'PSD'
    }
    mode_label = mode_labels.get(spectrum_mode, spectrum_mode)
    
    # è¨ˆç®—é »ç‡è§£æåº¦
    freq_resolution = sr / n_fft
    
    # ä½¿ç”¨æŒ‡å®šæ¨¡å¼ã€çª—å‡½æ•¸å’Œ FFT é»æ•¸è¨ˆç®—é »è­œ
    frequencies, magnitudes_db, unit = compute_spectrum_with_mode(
        audio, sr, mode=spectrum_mode, n_fft=n_fft, window=window_function
    )
    # å¥—ç”¨ A-weighting (å¦‚æœå•Ÿç”¨)
    if use_a_weighting:
        magnitudes_db = apply_a_weighting(frequencies, magnitudes_db)
        weight_label = f"{unit}(A)" if unit != 'dB/Hz' else "dB(A)/Hz"
    else:
        weight_label = unit
    
    # å¥—ç”¨æ ¡æº–åç§»
    magnitudes_db = magnitudes_db + calibration_offset
    cal_offset = calibration_offset
    
    st.subheader(f"ğŸ“ˆ é »è­œåˆ†æ [{mode_label}] - {weight_label}")
    st.caption(f"ğŸ’¡ æ¨¡å¼: {mode_label} | çª—å‡½æ•¸: {window_function.capitalize()} | é »ç‡è§£æåº¦: {freq_resolution:.2f} Hz")
    
    # æº–å‚™å…¶ä»–åˆ†é æ‰€éœ€çš„åœ–è¡¨
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        f"ğŸ“Š {mode_label}", 
        "ğŸ“ˆ Level vs Time", 
        "ğŸŒŠ æ³¢å½¢åœ–", 
        "ğŸ”¥ Spectrogram", 
        "ğŸ¼ 1/3 å€é »ç¨‹ (dB(A))",
        "ğŸŒ€ 3D Waterfall",
        "ğŸ“‘ ç¶œåˆè¦–åœ–"
    ])
    
    with tab1:
        # æ±ºå®šé¡¯ç¤ºç¯„åœ
        x_min = max(20, highpass_cutoff)
        
        # äº’å‹•å¼é »è­œåœ–
        fig = create_interactive_spectrum(
            frequencies, magnitudes_db,
            title=f"é »è­œåˆ†æ [{mode_label}] - {weight_label} (Res: {freq_resolution:.1f}Hz)",
            ylabel=f"å¹…åº¦ ({weight_label})",
            freq_range=(x_min, 20000)
        )
        st.plotly_chart(fig, use_container_width=True, key=f"spectrum_main_{highpass_cutoff}_{key_suffix}")
        
        # ä¿å­˜ FFT åœ–è¡¨åˆ° session_stateï¼Œä¾› PDF å ±å‘Šä½¿ç”¨
        st.session_state['fft_chart_figure'] = fig
        
        st.caption(f"â„¹ï¸ è¨­å®šåƒæ•¸: Window={window_function}, N_FFT={n_fft}, Mode={spectrum_mode}")

    with tab2:
        # Level vs Time åœ–è¡¨ï¼ˆä½¿ç”¨è‡ªå®šç¾©å¹³æ»‘åƒæ•¸ï¼‰
        # ä½¿ç”¨ audio_processed ä»¥åæ˜ æ¿¾æ³¢æ•ˆæœ
        level_time_fig = create_level_vs_time_chart(audio, sr, smooth_window=smooth_window, calibration_offset=cal_offset, use_a_weighting=use_a_weighting)
        st.plotly_chart(level_time_fig, use_container_width=True, key="level_vs_time")
        
        # ä¿å­˜ Level vs Time åœ–è¡¨åˆ° session_stateï¼Œä¾› PDF å ±å‘Šä½¿ç”¨
        st.session_state['level_time_chart_figure'] = level_time_fig
    
    with tab3:
        # æ³¢å½¢åœ–
        wave_fig = create_waveform_chart(audio, sr, title="éŸ³è¨Šæ³¢å½¢åœ– (Waveform)")
        st.plotly_chart(wave_fig, use_container_width=True, key="waveform")
        
    with tab4:
        # Spectrogram
        spec_fig = create_spectrogram_chart(
            audio, sr, 
            use_a_weighting=use_a_weighting,
            z_range=spectrogram_z_range,
            calibration_offset=cal_offset,
            spl_offset=spectrogram_spl_offset
        )
        st.plotly_chart(spec_fig, use_container_width=True, key="spectrogram_main")
        
    with tab5:
        # 1/3 Octave
        octave_fig = create_octave_band_chart(
            audio, sr, 
            use_a_weighting=True, # å€é »ç¨‹é€šå¸¸ä½¿ç”¨ A-weighting
            calibration_offset=cal_offset
        )
        st.plotly_chart(octave_fig, use_container_width=True, key="octave_main")
        
        # ä¿å­˜ 1/3 Octave åœ–è¡¨åˆ° session_stateï¼Œä¾› PDF å ±å‘Šä½¿ç”¨
        st.session_state['octave_chart_figure'] = octave_fig
        
    with tab6:
        # 3D Waterfall
        waterfall_fig = create_waterfall_3d_chart(audio, sr)
        st.plotly_chart(waterfall_fig, use_container_width=True, key="waterfall")
        st.info("ğŸ’¡ 3D Waterfall åœ–å¯æ—‹è½‰ã€ç¸®æ”¾ã€‚æ‹–æ›³å¯æ”¹è®Šè¦–è§’ï¼Œæ»¾è¼ªç¸®æ”¾ã€‚")
    
    with tab7:
        combined_fig = create_combined_analysis_chart(
            audio, sr, frequencies, magnitudes_db,
            calibration_offset=cal_offset,
            spl_offset=spectrogram_spl_offset,
            z_range=spectrogram_z_range,
            use_a_weighting=use_a_weighting,
            smooth_window=smooth_window
        )
        st.plotly_chart(combined_fig, use_container_width=True, key="combined")
    
    st.markdown("---")


def run_discrete_tone_analysis(audio, sr, spectrum_mode='average', window_function='hann', n_fft=8192, use_a_weighting=True, ecma_standard='ECMA-74', highpass_cutoff=0, key_suffix="", removed_bands_keys=None):
    """åŸ·è¡Œ Discrete Tone æª¢æ¸¬
    
    Args:
        audio: éŸ³è¨Šè³‡æ–™
        sr: å–æ¨£ç‡
        spectrum_mode: é »è­œåˆ†ææ¨¡å¼ (average/peak_hold/psd)
        window_function: çª—å‡½æ•¸ (hann/hamming/blackman/flattop)
        n_fft: FFT é»æ•¸
        use_a_weighting: æ˜¯å¦ä½¿ç”¨ A-weighting
        ecma_standard: ä½¿ç”¨çš„åˆ¤å®šæ¨™æº– (ECMA-74 æˆ– ECMA-418)
        highpass_cutoff: é«˜é€šæ¿¾æ³¢æˆªæ­¢é »ç‡ (ç”¨æ–¼åœ–è¡¨é¡¯ç¤º)
    """
    from core.discrete_tone import detect_discrete_tones
    from core.fft import compute_average_spectrum, compute_peak_hold_spectrum, compute_psd, get_frequency_range
    from utils.interactive_plots import create_discrete_tone_chart
    
    # ä½¿ç”¨ç•¶å‰é¸æ“‡çš„é »è­œæ¨¡å¼å’Œ ECMA æ¨™æº–é€²è¡Œ Discrete Tone æª¢æ¸¬
    result = detect_discrete_tones(audio, sr, spectrum_mode=spectrum_mode, 
                                   window_function=window_function, n_fft=n_fft,
                                   ecma_standard=ecma_standard)
    
    # æ¨¡å¼åç¨±å°æ‡‰
    mode_names = {
        'average': 'FFT Average',
        'peak_hold': 'FFT Peak Hold',
        'psd': 'PSD'
    }
    mode_display = mode_names.get(spectrum_mode, spectrum_mode)
    
    # å–®ä½æ¨™ç±¤
    unit_label = "dB(A)" if use_a_weighting else "dB"
    
    # åˆ†ææ¨¡å¼å°æ‡‰çš„æ¨™ç±¤
    spectrum_mode_labels = {
        'average': 'FFT Average',
        'peak_hold': 'FFT Peak Hold',
        'psd': 'PSD'
    }

    # åŸ·è¡Œæª¢æ¸¬
    result = detect_discrete_tones(
        audio, sr, 
        ecma_standard=ecma_standard,
        n_fft=n_fft,
        spectrum_mode=spectrum_mode,
        window_function=window_function,
        use_a_weighting=use_a_weighting # å·²æ”¯æ´ï¼šåƒ…å½±éŸ¿å›å‚³çš„ spectrum æ•¸æ“šç”¨æ–¼çµ±ä¸€é¡¯ç¤º
    )
    
    # === éæ¿¾æ‰ä½æ–¼ã€Œå·²ç§»é™¤é »å¸¶ã€å…§çš„å‡è­¦å ± ===
    if result["tone_detected"] and removed_bands_keys:
        # å®šç¾©é »å¸¶ç¯„åœ (å¿…é ˆèˆ‡ Sidebar å®šç¾©ä¸€è‡´)
        # ç‚ºäº†å®‰å…¨èµ·è¦‹ï¼Œç¨å¾®æ”¾å¯¬é‚Šç•Œï¼Œç¢ºä¿é‚Šç·£çš„é‹¸é½’å³°å€¼ä¹Ÿè¢«éæ¿¾
        BAND_RANGES = {
            'low_freq': (0, 500),          # 20-500Hz (å»¶ä¼¸è‡³0ä»¥é˜²è¬ä¸€)
            'mid_freq': (500, 2000),       # 500-2kHz
            'mid_high_freq': (2000, 6000), # 2-6kHz
            'high_freq': (6000, 12000),    # 6-12kHz
            'ultra_high_freq': (12000, 24000) # 12-20kHz+
        }
        
        filtered_tones = []
        for tone in result['tones']:
            tone_freq = tone['frequency']
            is_removed = False
            
            # æª¢æŸ¥æ­¤ Tone æ˜¯å¦è½å…¥ä»»ä½•ä¸€å€‹è¢«ç§»é™¤çš„å€é–“
            for band_key in removed_bands_keys:
                if band_key in BAND_RANGES:
                    f_min, f_max = BAND_RANGES[band_key]
                    if f_min <= tone_freq <= f_max:
                        is_removed = True
                        break
            
            # åªæœ‰æœªè¢«ç§»é™¤çš„ Tone æ‰ä¿ç•™
            if not is_removed:
                filtered_tones.append(tone)
                
        # æ›´æ–°çµæœ
        result['tones'] = filtered_tones
        result['tone_detected'] = len(filtered_tones) > 0

    # å–å¾—æ ¡æº–åç§»
    discrete_tone_cal_offset = st.session_state.get('calibration_offset', 0.0)
    
    # é¡¯ç¤ºæª¢æ¸¬çµæœ
    st.subheader(f"ğŸµ Discrete Tone æª¢æ¸¬ ({ecma_standard}) - {spectrum_mode_labels.get(spectrum_mode, spectrum_mode)}")
    st.caption(f"ğŸ’¡ æç¤º: ç´…è‰²æ˜Ÿè™Ÿæ¨™è¨˜è¶…éé–€æª»çš„ Discrete Toneï¼Œç°è‰²ä¸‰è§’å½¢ç‚ºå€™é¸å³°å€¼")
    
    # æ±ºå®šé¡¯ç¤ºç¯„åœ X è»¸
    x_min = max(20, highpass_cutoff)
    
    tone_fig = create_discrete_tone_chart(
        result['frequencies'], 
        result['magnitudes'], 
        result['tones'],
        result.get('all_candidates', []),
        title=f"Discrete Tone æª¢æ¸¬çµæœ ({ecma_standard} æ¨™æº–) - {spectrum_mode_labels.get(spectrum_mode, spectrum_mode)}",
        use_a_weighting=use_a_weighting,
        ecma_standard=ecma_standard,
        calibration_offset=discrete_tone_cal_offset,
        freq_range=(x_min, 15000)
    )
    st.plotly_chart(tone_fig, use_container_width=True, key=f"discrete_tone_{highpass_cutoff}_{key_suffix}")
    
    # ç‹€æ…‹é¡¯ç¤º
    if result["tone_detected"]:
        st.warning(f"âš ï¸ åµæ¸¬åˆ° {len(result['tones'])} å€‹ Discrete Tone!")
        
        # é¡¯ç¤ºè©³ç´°åˆ—è¡¨
        for i, tone in enumerate(result['tones'], 1):
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                st.metric(f"Tone #{i} é »ç‡", f"{tone['frequency']:.0f} Hz")
            with col2:
                st.metric("PR (Î”Lp)", f"{tone['prominence']:.1f} dB")
            with col3:
                st.metric("TNR (Î”Lt)", f"{tone.get('tnr', 0):.1f} dB")
            with col4:
                st.metric("åˆ¤å®šæ–¹æ³•", tone.get('method', 'PR'))
            with col5:
                st.metric("é »å¸¶", tone['band'])
    else:
        st.success("âœ… æœªåµæ¸¬åˆ°é¡¯è‘—çš„ Discrete Tone")

    
    # é¡¯ç¤ºåˆ¤å®šæ¨™æº–
    st.caption(f"ğŸ“ åˆ¤å®šæ¨™æº–: {result.get('criteria', 'ECMA-418-1')}")
    
    # é¡¯ç¤ºå€™é¸ Tone
    if result.get("all_candidates"):
        with st.expander("ğŸ” æŸ¥çœ‹æ‰€æœ‰å€™é¸å³°å€¼ (ECMA-418-1 é›™æº–å‰‡)"):
            import pandas as pd
            candidates = result["all_candidates"]
            # è™•ç†æ–°èˆŠè³‡æ–™æ ¼å¼
            if candidates and 'tnr' in candidates[0]:
                df = pd.DataFrame(candidates)
                df = df[['frequency', 'prominence', 'tnr', 'pr_threshold', 'tnr_threshold', 'method', 'exceeds_threshold', 'band']]
                df.columns = ["é »ç‡ (Hz)", "PR (dB)", "TNR (dB)", "PRé–€æª»", "TNRé–€æª»", "åˆ¤å®šæ–¹æ³•", "è¶…éé–€æª»", "é »å¸¶"]
            else:
                df = pd.DataFrame(candidates)
                if not df.empty:
                    df.columns = ["é »ç‡ (Hz)", "çªå‡ºé‡ (dB)", "å¹…åº¦ (dB)", "é »å¸¶", "é–€æª» (dB)", "è¶…éé–€æª»"]
            st.dataframe(df, use_container_width=True)
    
    st.markdown("---")


def run_sop_analysis(audio, sr, sop_params):
    """åŸ·è¡Œ ASUS SOP é«˜é »éŸ³åˆ†æï¼ˆæ”¯æ´å¤šæ¨¡å¼ï¼‰"""
    from core.sop_analyzer import analyze_idle_mode, analyze_ue_mode, analyze_workload_mode
    import plotly.graph_objects as go
    import numpy as np
    
    # å–å¾—æ ¡æº–åç§»
    cal_offset = st.session_state.get('calibration_offset', 0.0)
    
    # å–å¾—è¦åˆ†æçš„æ¨¡å¼åˆ—è¡¨
    modes = sop_params.get('modes', [sop_params.get('mode', 'IDLE')])
    
    if not modes:
        st.warning("è«‹é¸æ“‡è‡³å°‘ä¸€å€‹ SOP æ¨¡å¼é€²è¡Œåˆ†æ")
        return
    
    st.subheader(f"âš¡ ASUS SOW é«˜é »éŸ³åˆ†æ")
    
    # é¡¯ç¤ºæ ¡æº–ç‹€æ…‹
    if cal_offset != 0:
        st.caption(f"ğŸ“Œ å·²å¥—ç”¨æ ¡æº–åç§»: **{cal_offset:+.1f} dB**")
    
    # å„²å­˜åˆ†æçµæœä¾›å ±å‘Šä½¿ç”¨
    sop_results = {}
    
    # ===== IDLE æ¨¡å¼ =====
    if 'IDLE' in modes:
        st.markdown("### ğŸ”‡ IDLE Mode")
        spec_limit = sop_params.get('idle_spec', 20.0)
        
        adjusted_spec = spec_limit - cal_offset
        result = analyze_idle_mode(audio, sr, adjusted_spec)
        sop_results['IDLE'] = result
        
        max_leq = result['max_leq'] + cal_offset
        leqs_calibrated = np.array(result['leqs']) + cal_offset
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Max Leq", f"{max_leq:.1f} dBA")
        with col2:
            st.metric("åˆ¤å®šçµæœ", "PASS" if result['is_pass'] else "FAIL")
        
        if not result['is_pass']:
            st.error(f"âŒ æª¢æ¸¬å¤±æ•—ï¼šæœ‰éƒ¨åˆ†æ•¸æ“šé»è¶…éç®¡åˆ¶ç·š {spec_limit} dBA")
        else:
            st.success(f"âœ… æª¢æ¸¬é€šéï¼šæ‰€æœ‰æ•¸æ“šé»éƒ½åœ¨ç®¡åˆ¶ç·š {spec_limit} dBA ä»¥ä¸‹")
            
        # ç¹ªè£½è¶¨å‹¢åœ–
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=result['times'], 
            y=leqs_calibrated.tolist(), 
            name="Moving Leq (10s)",
            hovertemplate='<b>%{x:.1f}s</b> | %{y:.1f} dBA<extra></extra>'
        ))
        fig.add_hline(y=spec_limit, line_dash="dash", line_color="red", 
                      annotation_text=f"SPEC: {spec_limit} dBA")
        fig.update_layout(
            title="IDLE Mode 10s Moving Average è¶¨å‹¢åœ–", 
            xaxis_title="æ™‚é–“ (ç§’)", 
            yaxis_title="éŸ³å£“ç´š (dBA)",
            xaxis=dict(showspikes=True, spikemode='across', spikesnap='cursor',
                       spikecolor='red', spikethickness=1, spikedash='dot'),
            yaxis=dict(showspikes=False),
            hovermode='x',
            hoverlabel=dict(bgcolor='rgba(255,255,255,0.95)', 
                           bordercolor='rgba(100,100,100,0.3)', font_size=11)
        )
        st.plotly_chart(fig, use_container_width=True)
        st.markdown("---")
    
    # ===== UE æ¨¡å¼ =====
    if 'UE' in modes:
        st.markdown("### ğŸ‘¤ UE Mode")
        ue_spec = sop_params.get('ue_spec', 22.0)
        result = analyze_ue_mode(audio, sr)
        sop_results['UE'] = result
        
        leq_calibrated = result['leq'] + cal_offset
        is_pass = leq_calibrated <= ue_spec
        result['is_pass'] = is_pass  # æ·»åŠ åˆ¤å®šçµæœ
        result['spec'] = ue_spec  # è¨˜éŒ„ SPEC
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ•´æ®µå¹³å‡ Leq", f"{leq_calibrated:.1f} dBA")
        with col2:
            st.metric("åˆ¤å®šçµæœ", "PASS" if is_pass else "FAIL")
        
        if is_pass:
            st.success(f"âœ… æª¢æ¸¬é€šéï¼šå¹³å‡ Leq {leq_calibrated:.1f} dBA â‰¤ ç®¡åˆ¶ç·š {ue_spec} dBA")
        else:
            st.error(f"âŒ æª¢æ¸¬å¤±æ•—ï¼šå¹³å‡ Leq {leq_calibrated:.1f} dBA > ç®¡åˆ¶ç·š {ue_spec} dBA")
        
        st.info(f"éŒ„éŸ³æ™‚é•·: {result['duration']:.1f} ç§’")
        st.markdown("---")
    
    # ===== Workload æ¨¡å¼ =====
    if 'Workload' in modes:
        st.markdown("### âš¡ Workload Mode")
        spec_fail = sop_params.get('work_spec_fail', 22.0)
        spec_max = sop_params.get('work_spec_max', 28.0)
        
        adjusted_spec_fail = spec_fail - cal_offset
        adjusted_spec_max = spec_max - cal_offset
        result = analyze_workload_mode(audio, sr, adjusted_spec_fail, adjusted_spec_max)
        sop_results['Workload'] = result
        
        max_leq = result['max_leq'] + cal_offset
        leqs_calibrated = np.array(result['leqs']) + cal_offset
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Max Leq", f"{max_leq:.1f} dBA")
        with col2:
            st.metric(f"Fail Rate (>{spec_fail})", f"{result['fail_rate']}%")
        with col3:
            st.metric("æ•´é«”çµæœ", "PASS" if result['is_pass'] else "FAIL")
            
        if not result['criteria_max_pass']:
            st.error(f"âŒ Max å€¼è¶…éç®¡åˆ¶ç·š {spec_max} dBA")
        if not result['criteria_rate_pass']:
            st.error(f"âŒ Fail Rate ({result['fail_rate']}%) è¶…é 2% é–€æª»")
            
        # ç¹ªè£½è¶¨å‹¢åœ–
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=result['times'], 
            y=leqs_calibrated.tolist(), 
            name="Moving Leq (1s)",
            hovertemplate='<b>%{x:.1f}s</b> | %{y:.1f} dBA<extra></extra>'
        ))
        fig.add_hline(y=spec_fail, line_dash="dot", line_color="orange", 
                      annotation_text=f"Fail Rate Limit: {spec_fail} dBA")
        fig.add_hline(y=spec_max, line_dash="dash", line_color="red", 
                      annotation_text=f"Max Limit: {spec_max} dBA")
        fig.update_layout(
            title="Workload Mode 1s Moving Average è¶¨å‹¢åœ–", 
            xaxis_title="æ™‚é–“ (ç§’)", 
            yaxis_title="éŸ³å£“ç´š (dBA)",
            xaxis=dict(showspikes=True, spikemode='across', spikesnap='cursor',
                       spikecolor='red', spikethickness=1, spikedash='dot'),
            yaxis=dict(showspikes=False),
            hovermode='x',
            hoverlabel=dict(bgcolor='rgba(255,255,255,0.95)', 
                           bordercolor='rgba(100,100,100,0.3)', font_size=11)
        )
        st.plotly_chart(fig, use_container_width=True)
        st.markdown("---")
    
    # å„²å­˜çµæœåˆ° session_state ä¾›å ±å‘Šä½¿ç”¨
    st.session_state['sop_results'] = sop_results



def run_band_filter_analysis(audio, sr, removed_bands):
    """åŸ·è¡Œé »å¸¶éæ¿¾æ¨¡æ“¬åˆ†æ"""
    from core.fft import compute_average_spectrum, get_frequency_range
    from core.filters import bandpass_filter
    from core.noise_level import calculate_rms, rms_to_db
    from utils.interactive_plots import create_band_filter_comparison
    import numpy as np
    
    st.subheader("ğŸšï¸ é »å¸¶éæ¿¾æ¨¡æ“¬")
    st.caption("æ¨¡æ“¬ç§»é™¤ç‰¹å®šé »å¸¶å¾Œçš„é »è­œè®ŠåŒ–")
    
    # é »å¸¶å®šç¾©
    band_ranges = {
        'low_freq': (20, 500),
        'mid_freq': (500, 2000),
        'mid_high_freq': (2000, 6000),
        'high_freq': (6000, 12000),
        'ultra_high_freq': (12000, 20000)
    }
    
    band_names = {
        'low_freq': 'ä½é » (é¢¨æ‰‡/é¦¬é”)',
        'mid_freq': 'ä¸­é » (æ©Ÿæ¢°é‹è½‰)',
        'mid_high_freq': 'ä¸­é«˜é » (éµç›¤è²)',
        'high_freq': 'é«˜é » (é›»æ„Ÿå˜¯å«)',
        'ultra_high_freq': 'è¶…é«˜é »'
    }
    
    # é¡¯ç¤ºç§»é™¤çš„é »å¸¶
    st.info(f"ğŸ”‡ å·²ç§»é™¤çš„é »å¸¶: {', '.join([band_names.get(b, b) for b in removed_bands])}")
    
    # è¨ˆç®—åŸå§‹é »è­œ
    freqs_orig, mags_orig = compute_average_spectrum(audio, sr)
    
    # å»ºç«‹éæ¿¾å¾Œçš„è¨Šè™Ÿ (é€šéä¿ç•™æœªè¢«ç§»é™¤çš„é »å¸¶)
    nyquist = sr / 2
    audio_filtered = np.zeros_like(audio)
    
    for band_name, (low, high) in band_ranges.items():
        if band_name not in removed_bands:
            # ç¢ºä¿é »ç‡åœ¨æœ‰æ•ˆç¯„åœå…§
            low = max(20, low)
            high = min(high, nyquist - 1)
            if low < high:
                try:
                    band_audio = bandpass_filter(audio, sr, low, high)
                    audio_filtered += band_audio
                except:
                    pass
    
    # è¨ˆç®—éæ¿¾å¾Œé »è­œ
    freqs_filt, mags_filt = compute_average_spectrum(audio_filtered, sr)
    
    # é™åˆ¶é¡¯ç¤ºç¯„åœ
    freq_min, freq_max = 20, min(20000, sr // 2)
    freqs_orig, mags_orig = get_frequency_range(freqs_orig, mags_orig, freq_min, freq_max)
    freqs_filt, mags_filt = get_frequency_range(freqs_filt, mags_filt, freq_min, freq_max)
    
    # ç¹ªè£½äº’å‹•å¼å°æ¯”åœ–
    filter_fig = create_band_filter_comparison(
        freqs_orig, mags_orig, mags_filt, removed_bands,
        title="é »å¸¶éæ¿¾å‰å¾Œå°æ¯”"
    )
    st.plotly_chart(filter_fig, use_container_width=True)
    
    # è¨ˆç®—èƒ½é‡è®ŠåŒ–
    col1, col2, col3 = st.columns(3)
    
    rms_orig = calculate_rms(audio)
    rms_filt = calculate_rms(audio_filtered)
    db_orig = rms_to_db(rms_orig, 1.0)
    db_filt = rms_to_db(rms_filt, 1.0)
    db_reduction = db_orig - db_filt
    
    with col1:
        st.metric("åŸå§‹èƒ½é‡", f"{db_orig:.1f} dB")
    with col2:
        st.metric("éæ¿¾å¾Œèƒ½é‡", f"{db_filt:.1f} dB")
    with col3:
        st.metric("èƒ½é‡é™ä½", f"{db_reduction:.1f} dB", delta=f"-{db_reduction:.1f}")
    
    st.markdown("---")


def apply_band_filter(audio, sr, removed_bands):
    """å¥—ç”¨é »å¸¶éæ¿¾ï¼Œç§»é™¤æŒ‡å®šé »å¸¶
    
    Args:
        audio: åŸå§‹éŸ³è¨Šè³‡æ–™
        sr: å–æ¨£ç‡
        removed_bands: è¦ç§»é™¤çš„é »å¸¶åˆ—è¡¨
    
    Returns:
        éæ¿¾å¾Œçš„éŸ³è¨Šè³‡æ–™
    """
    from core.filters import bandpass_filter
    import numpy as np
    
    # é »å¸¶å®šç¾©
    band_ranges = {
        'low_freq': (20, 500),
        'mid_freq': (500, 2000),
        'mid_high_freq': (2000, 6000),
        'high_freq': (6000, 12000),
        'ultra_high_freq': (12000, 20000)
    }
    
    nyquist = sr / 2
    audio_filtered = np.zeros_like(audio)
    
    # åªä¿ç•™æœªè¢«ç§»é™¤çš„é »å¸¶
    for band_name, (low, high) in band_ranges.items():
        if band_name not in removed_bands:
            low = max(20, low)
            high = min(high, nyquist - 1)
            if low < high:
                try:
                    band_audio = bandpass_filter(audio, sr, low, high)
                    audio_filtered += band_audio
                except:
                    pass
    
    return audio_filtered


def run_band_filter_comparison(audio_original, audio_filtered, sr, removed_bands):
    """é¡¯ç¤ºåŸå§‹èˆ‡éæ¿¾å¾Œçš„é »è­œå°æ¯”"""
    from core.fft import compute_average_spectrum, get_frequency_range
    from core.noise_level import calculate_rms, rms_to_db
    from utils.interactive_plots import create_band_filter_comparison
    
    st.subheader("ğŸšï¸ é »å¸¶éæ¿¾æ•ˆæœå°æ¯”")
    
    band_names = {
        'low_freq': 'ä½é » (é¢¨æ‰‡/é¦¬é”)',
        'mid_freq': 'ä¸­é » (æ©Ÿæ¢°é‹è½‰)',
        'mid_high_freq': 'ä¸­é«˜é » (éµç›¤è²)',
        'high_freq': 'é«˜é » (é›»æ„Ÿå˜¯å«)',
        'ultra_high_freq': 'è¶…é«˜é »'
    }
    
    st.info(f"ğŸ”‡ å·²ç§»é™¤çš„é »å¸¶: {', '.join([band_names.get(b, b) for b in removed_bands])}")
    
    # è¨ˆç®—åŸå§‹å’Œéæ¿¾å¾Œé »è­œ
    freqs_orig, mags_orig = compute_average_spectrum(audio_original, sr)
    freqs_filt, mags_filt = compute_average_spectrum(audio_filtered, sr)
    
    freq_min, freq_max = 20, min(20000, sr // 2)
    freqs_orig, mags_orig = get_frequency_range(freqs_orig, mags_orig, freq_min, freq_max)
    freqs_filt, mags_filt = get_frequency_range(freqs_filt, mags_filt, freq_min, freq_max)
    
    # ç¹ªè£½å°æ¯”åœ–
    filter_fig = create_band_filter_comparison(
        freqs_orig, mags_orig, mags_filt, removed_bands,
        title="åŸå§‹é »è­œ vs éæ¿¾å¾Œé »è­œ"
    )
    st.plotly_chart(filter_fig, use_container_width=True)
    
    # èƒ½é‡è®ŠåŒ–
    col1, col2, col3 = st.columns(3)
    
    rms_orig = calculate_rms(audio_original)
    rms_filt = calculate_rms(audio_filtered)
    db_orig = rms_to_db(rms_orig, 1.0)
    db_filt = rms_to_db(rms_filt, 1.0)
    db_reduction = db_orig - db_filt
    
    with col1:
        st.metric("åŸå§‹èƒ½é‡", f"{db_orig:.1f} dB")
    with col2:
        st.metric("éæ¿¾å¾Œèƒ½é‡", f"{db_filt:.1f} dB")
    with col3:
        st.metric("èƒ½é‡é™ä½", f"{db_reduction:.1f} dB", delta=f"-{db_reduction:.1f}")
    
    st.markdown("---")


def process_batch_analysis(uploaded_files, analyze_sop=False, sop_params=None):
    """åŸ·è¡Œæ‰¹æ¬¡åˆ†æ"""
    import pandas as pd
    import tempfile
    import os
    from core.audio_loader import load_audio, validate_audio
    from core.noise_level import calculate_noise_level
    from core.fft import compute_average_spectrum
    from core.sop_analyzer import analyze_idle_mode, analyze_ue_mode, analyze_workload_mode
    from core.band_analyzer import compute_octave_bands
    
    batch_results = {}
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    count = len(uploaded_files)
    
    for i, file in enumerate(uploaded_files):
        status_text.text(f"æ­£åœ¨åˆ†æ ({i+1}/{count}): {file.name}...")
        
        # Save temp
        suffix = f".{file.name.split('.')[-1]}"
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp.write(file.getvalue())
            tmp_path = tmp.name
            
        try:
            # 1. Validate Audio
            validation = validate_audio(tmp_path, strict=False)
            
            # 2. Load Audio
            audio, sr = load_audio(tmp_path)
            
            # 3. Noise Level
            noise = calculate_noise_level(audio, sr)
            
            # 4. SOP Analysis
            sop_res = None
            if analyze_sop:
                mode = sop_params.get('mode', 'IDLE')
                if mode == "IDLE":
                    sop_res = analyze_idle_mode(audio, sr, sop_params.get('idle_spec', 20.0))
                elif mode == "UE":
                    sop_res = analyze_ue_mode(audio, sr)
                elif mode == "Workload":
                    sop_res = analyze_workload_mode(audio, sr, sop_params.get('work_spec_fail', 22.0), sop_params.get('work_spec_max', 28.0))
            
            # 5. Spectrum
            freqs, mags = compute_average_spectrum(audio, sr)
            
            # 6. 1/3 Octave Bands
            octave = compute_octave_bands(audio, sr, use_a_weighting=True)
            
            # Store Result
            batch_results[file.name] = {
                "noise": noise,
                "sop": sop_res,
                "spectrum": {"freqs": freqs, "mags": mags},
                "octave": octave,
                "sr": sr,
                "duration": len(audio)/sr,
                "audio": audio, # Save raw audio
                "validation": validation # Save validation info
            }
            
        except Exception as e:
            st.error(f"åˆ†æ {file.name} å¤±æ•—: {e}")
            
        finally:
            try:
                os.unlink(tmp_path)
            except:
                pass
            
        progress_bar.progress((i + 1) / count)
        
    st.session_state['batch_data'] = batch_results
    status_text.success("æ‰¹æ¬¡åˆ†æå®Œæˆ!")
    st.rerun()


def render_batch_dashboard(
    highpass_cutoff,
    analyze_noise,
    analyze_spectrum,
    analyze_discrete_tone,
    analyze_sop,
    sop_params,
    analyze_high_freq,
    analyze_band_filter,
    removed_bands,
    use_a_weighting,
    spectrum_mode,
    window_function,
    n_fft=8192,
    smooth_window_size=1
):
    """é¡¯ç¤ºæ‰¹æ¬¡åˆ†æå„€è¡¨æ¿"""
    import plotly.graph_objects as go
    import numpy as np
    
    data = st.session_state.get('batch_data', {})
    if not data:
        return

    st.header("ğŸ“Š æ‰¹æ¬¡åˆ†ææ¯”è¼ƒå„€è¡¨æ¿")
    
    # 1. Comparison Table
    st.subheader("1. æ•¸æ“šç¸½è¡¨")
    table_rows = []
    
    for name, res in data.items():
        n = res['noise']
        sop = res.get('sop')
        
        row = {
            "Filename": name,
            "Leq (dBA)": n['leq_dba'],
            "Lmax": n['lmax_dba'],
            "L90": n['l90']
        }
        
        # SOP Result
        if sop:
            row["SOP Mode"] = sop['mode']
            row["SOP Result"] = "PASS" if sop.get('is_pass', True) else "FAIL"
            if sop['mode'] == "UE":
                row["SOP Val (Avg)"] = sop['leq']
            else:
                row["SOP Val (Max)"] = sop['max_leq']
        
        table_rows.append(row)
    
    import pandas as pd
    df = pd.DataFrame(table_rows)
    st.dataframe(df, use_container_width=True)
    
    st.download_button(
        label="â¬‡ï¸ ä¸‹è¼‰æ¯”è¼ƒç¸½è¡¨ (CSV)",
        data=df.to_csv(index=False).encode('utf-8-sig'),
        file_name=f"Batch_Summary_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
        mime="text/csv"
    )
    

    # File Selector for Comparison Charts
    st.subheader("2. è©³ç´°æ¯”è¼ƒåˆ†æ")
    st.caption("å»ºè­°é¸æ“‡ 2-3 å€‹æª”æ¡ˆé€²è¡Œè©³ç´°æ¯”è¼ƒï¼Œä»¥å…ç•«é¢éæ–¼æ“æ“ ")
    selected_files = st.multiselect("é¸æ“‡è¦æ¯”è¼ƒçš„æª”æ¡ˆ", options=list(data.keys()), default=list(data.keys())[:2])
    
    if not selected_files:
        st.info("è«‹é¸æ“‡è‡³å°‘ä¸€å€‹æª”æ¡ˆé€²è¡Œæ¯”è¼ƒ")
        return

    # Import visualization tools
    from utils.interactive_plots import (
        create_spectrogram_chart,
        create_waterfall_3d_chart,
        create_octave_band_chart
    )
    
    # 1. 1/3 Octave Comparison (Grouped Bar)
    st.markdown("#### 1/3 å€é »ç¨‹æ¯”è¼ƒ (Grouped Bar)")
    fig_oct = go.Figure()
    
    for name in selected_files:
        oct_data = data[name]['octave']
        # Use Bar for grouped comparison
        fig_oct.add_trace(go.Bar(
            x=oct_data['nominal_freqs'],
            y=oct_data['band_levels'],
            name=name,
            opacity=0.8
        ))
        
    fig_oct.update_layout(
        title="1/3 å€é »ç¨‹é »è­œæ¯”è¼ƒ",
        xaxis_title="é »ç‡ (Hz)",
        yaxis_title="éŸ³å£“ç´š dB(A)",
        xaxis_type="log",
        barmode='group', # Grouped bars
        hovermode="x unified"
    )
    st.plotly_chart(fig_oct, use_container_width=True)

    # 2. FFT Comparison (Line)
    st.markdown("#### FFT ç´°éƒ¨é »è­œæ¯”è¼ƒ (Overlay)")
    fig_fft = go.Figure()
    for name in selected_files:
        spec = data[name]['spectrum']
        mask = spec['freqs'] <= 20000
        x_vals = spec['freqs'][mask]
        y_vals = spec['mags'][mask]
        
        fig_fft.add_trace(go.Scatter(
            x=x_vals, 
            y=y_vals,
            name=name,
            mode='lines',
            line=dict(width=1)
        ))
    fig_fft.update_layout(
        title="FFT å¹³å‡é »è­œæ¯”è¼ƒ",
        xaxis_title="é »ç‡ (Hz)",
        yaxis_title="å¹…åº¦ (dB)",
        hovermode="x unified",
        xaxis_type="log"
    )
    st.plotly_chart(fig_fft, use_container_width=True)
    
    # 3. Level vs Time
    st.markdown("#### å™ªéŸ³ç­‰ç´šè¶¨å‹¢ (Level vs Time)")
    fig_time = go.Figure()
    has_profile = False
    
    for name in selected_files:
        profile = data[name]['noise'].get('profile', {})
        if profile and 'times' in profile and 'levels' in profile:
            has_profile = True
            times = profile['times']
            levels = profile['levels']
            
            # å¥—ç”¨å¹³æ»‘è™•ç† (æ¯”è¼ƒæ¨¡å¼åŒæ¨£å—å…¨åŸŸè¨­å®šå½±éŸ¿)
            if smooth_window_size > 1:
                kernel = np.ones(smooth_window_size) / smooth_window_size
                levels = np.convolve(levels, kernel, mode='same')
            
            if len(times) > 5000:
                step = len(times) // 5000
                times = times[::step]
                levels = levels[::step]
            
            fig_time.add_trace(go.Scatter(
                x=times, 
                y=levels,
                name=name,
                mode='lines',
                line=dict(width=1.5)
            ))
            
    if has_profile:
        fig_time.update_layout(
            title="å™ªéŸ³ç­‰ç´šè¶¨å‹¢æ¯”è¼ƒ (Leq Profile)",
            xaxis_title="æ™‚é–“ (ç§’)",
            yaxis_title="éŸ³å£“ç´š dB(A)",
            hovermode="x unified"
        )
        st.plotly_chart(fig_time, use_container_width=True)

    # 4. Spectrogram Comparison (Side-by-side)
    st.markdown("#### Spectrogram å°ç…§æ¯”è¼ƒ")
    cols = st.columns(len(selected_files))
    for i, name in enumerate(selected_files):
        with cols[i]:
            st.markdown(f"**{name}**")
            audio_data = data[name].get('audio', None)
            sr_data = data[name].get('sr', 48000)
            if audio_data is not None:
                # Reuse existing function
                fig_spec = create_spectrogram_chart(audio_data, sr_data, title=f"Spectrogram: {name}", use_a_weighting=use_a_weighting)
                st.plotly_chart(fig_spec, use_container_width=True, key=f"batch_spec_{i}")
            else:
                st.warning("ç„¡éŸ³è¨Šæ•¸æ“š")

    # 5. 3D Waterfall Comparison (Side-by-side)
    st.markdown("#### 3D Waterfall å°ç…§æ¯”è¼ƒ")
    cols_water = st.columns(len(selected_files))
    for i, name in enumerate(selected_files):
        with cols_water[i]:
            st.markdown(f"**{name}**")
            audio_data = data[name].get('audio', None)
            sr_data = data[name].get('sr', 48000)
            if audio_data is not None:
                fig_water = create_waterfall_3d_chart(audio_data, sr_data)
                # Update title
                fig_water.update_layout(title=f"Waterfall: {name}")
                st.plotly_chart(fig_water, use_container_width=True, key=f"batch_water_{i}")
            else:
                st.warning("ç„¡éŸ³è¨Šæ•¸æ“š")

        
    # --- Detail Inspector ---
    st.markdown("---")
    st.header("ğŸ” å–®æª”è©³ç´°åˆ†ææª¢è¦– (Detail Inspector)")
    
    detail_file = st.selectbox("é¸æ“‡è¦æŸ¥çœ‹è©³ç´°å ±å‘Šçš„æª”æ¡ˆ", options=["(è«‹é¸æ“‡)"] + list(data.keys()))
    
    if detail_file and detail_file != "(è«‹é¸æ“‡)":
        target_data = data[detail_file]
        
        # Inject data into global session state to simulate Single File Mode
        st.session_state.audio_loaded = True
        st.session_state.audio_original = target_data['audio']
        st.session_state.sr = target_data['sr']
        st.session_state.audio_filename = detail_file
        # Fix: Inject validation info
        if 'validation' in target_data:
            st.session_state.validation = target_data['validation']
        else:
            # Fallback if old data present in session (should not happen if re-run)
            st.session_state.validation = {
                "file_valid": True,
                "sample_rate": target_data['sr'],
                "duration": target_data['duration'],
                "channels": 1,
                "bit_depth": 16, # Assume 16
                "file_size_mb": 0,
                "warnings": []
            }
        
        st.info(f"æ­£åœ¨é¡¯ç¤º **{detail_file}** çš„è©³ç´°åˆ†æçµæœ...")
        
        # Reuse the main analysis renderer
        # Ensure we capture current sidebar settings
        # We need to access the sidebar widget values. They are in 'main' scope...
        # But Streamlit widgets are global in session_state usually.
        # However, variables like 'highpass_cutoff' are passed as args.
        # We need to grab them from session_state or default?
        # Sidebar widgets were defined in 'main()'. They are local variables there.
        # WE CANNOT ACCESS 'highpass_cutoff' here easily unless we pass them or read session state keys.
        
        render_analysis_results(
            highpass_cutoff,
            analyze_noise,
            analyze_spectrum,
            analyze_discrete_tone,
            analyze_sop,
            sop_params,
            analyze_band_filter,
            removed_bands,
            use_a_weighting,
            spectrum_mode,
            window_function,
            n_fft
        )



if __name__ == "__main__":
    main()



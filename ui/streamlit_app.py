# -*- coding: utf-8 -*-
"""
è²å­¸æ¸¬è©¦ AI åˆ†æç³»çµ± - Streamlit Web UI

åŠŸèƒ½ (AUD-009):
- æª”æ¡ˆä¸Šå‚³ä»‹é¢
- åˆ†æçµæœé¡¯ç¤º
- é »è­œåœ–è¦–è¦ºåŒ–
- å ±å‘Šä¸‹è¼‰
"""

import streamlit as st
import tempfile
import os
from pathlib import Path
import sys
# åŠ å…¥å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from datetime import datetime
from utils.report import generate_excel_report


def main():
    """Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»å‡½æ•¸"""
    st.set_page_config(
        page_title="è²å­¸æ¸¬è©¦ AI åˆ†æç³»çµ±",
        page_icon="ğŸ”Š",
        layout="wide"
    )
    
    # åˆå§‹åŒ– session_state
    if 'audio_loaded' not in st.session_state:
        st.session_state.audio_loaded = False
    if 'audio_original' not in st.session_state:
        st.session_state.audio_original = None
    if 'sr' not in st.session_state:
        st.session_state.sr = None
    if 'validation' not in st.session_state:
        st.session_state.validation = None

    st.title("ğŸ”Š è²å­¸æ¸¬è©¦ AI åˆ†æç³»çµ±")
    st.markdown("*åŸºæ–¼ AI çš„ç­†è¨˜å‹é›»è…¦è²å­¸æ¸¬è©¦åˆ†æç³»çµ±*")
    st.markdown("---")

    # å´é‚Šæ¬„è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ åˆ†æè¨­å®š")
        
        # === HEAD ArtemiS å°é½ŠåŠŸèƒ½ ===
        st.subheader("ğŸ“Š é »è­œåˆ†ææ¨¡å¼")
        spectrum_mode = st.selectbox(
            "åˆ†ææ¨¡å¼",
            options=['average', 'peak_hold', 'psd'],
            format_func=lambda x: {
                'average': 'ğŸ“Š FFT Average (å¹³å‡)',
                'peak_hold': 'ğŸ“ˆ FFT Peak Hold (å³°å€¼ä¿æŒ)',
                'psd': 'ğŸ“‰ PSD (åŠŸç‡é »è­œå¯†åº¦)'
            }.get(x, x),
            help="Average: æ™‚é–“å¹³å‡ | Peak Hold: å–æœ€å¤§å€¼ | PSD: åŠŸç‡æ­¸ä¸€åŒ–åˆ° 1 Hz"
        )
        
        window_function = st.selectbox(
            "çª—å‡½æ•¸",
            options=['hann', 'hamming', 'blackman', 'flattop'],
            format_func=lambda x: {
                'hann': 'ğŸ”” Hann (é€šç”¨)',
                'hamming': 'ğŸ”· Hamming (æ›´ä½³æ—ç“£æŠ‘åˆ¶)',
                'blackman': 'âš« Blackman (æœ€ä½³æ—ç“£æŠ‘åˆ¶)',
                'flattop': 'â¬œ Flat Top (å¹…åº¦ç²¾ç¢º)'
            }.get(x, x),
            help="Hann: 95% æ‡‰ç”¨é©ç”¨ | Blackman: éœ€æ¥µä½³æ—ç“£æŠ‘åˆ¶ | Flat Top: å¹…åº¦æ ¡æº–"
        )
        
        highpass_cutoff = st.slider(
            "é«˜é€šæ¿¾æ³¢æˆªæ­¢é »ç‡ (Hz)",
            min_value=1000, max_value=8000, value=4000, step=500,
            help="ç”¨æ–¼é«˜é »éŸ³éš”é›¢åˆ†æ"
        )
        
        st.markdown("---")
        
        st.subheader("ğŸ“‹ åˆ†æé¸é …")
        analyze_noise = st.checkbox("å™ªéŸ³ç­‰ç´šåˆ†æ dB(A)", value=True)
        analyze_spectrum = st.checkbox("FFT é »è­œåˆ†æ", value=True)
        
        # A-weighting é¸é … (é è¨­å•Ÿç”¨)
        use_a_weighting = st.checkbox(
            "ğŸ‘‚ å¥—ç”¨ A-weighting åŠ æ¬Š", 
            value=True,
            help="A-weighting æ¨¡æ“¬äººè€³å°ä¸åŒé »ç‡çš„æ•æ„Ÿåº¦ï¼Œç¬¦åˆ IEC 61672-1 æ¨™æº–"
        )
        
        analyze_discrete_tone = st.checkbox("Discrete Tone æª¢æ¸¬", value=True)
        analyze_high_freq = st.checkbox("é«˜é »éŸ³éš”é›¢åˆ†æ", value=True)
        analyze_band_filter = st.checkbox("ğŸšï¸ é »å¸¶éæ¿¾æ¨¡æ“¬", value=False)
        
        # é »å¸¶é¸æ“‡å™¨
        removed_bands = []
        if analyze_band_filter:
            st.markdown("---")
            st.subheader("ğŸšï¸ é »å¸¶éæ¿¾æ¨¡æ“¬")
            st.caption("é¸æ“‡è¦ç§»é™¤çš„é »å¸¶ï¼Œæ¨¡æ“¬å»é™¤ç‰¹å®šå™ªéŸ³ä¾†æºçš„æ•ˆæœ")
            
            remove_low = st.checkbox("ç§»é™¤ä½é » (20-500Hz) - é¢¨æ‰‡/é¦¬é”", value=False, key="rm_low")
            remove_mid = st.checkbox("ç§»é™¤ä¸­é » (500-2kHz) - æ©Ÿæ¢°é‹è½‰", value=False, key="rm_mid")
            remove_mid_high = st.checkbox("ç§»é™¤ä¸­é«˜é » (2-6kHz) - éµç›¤è²", value=False, key="rm_mid_high")
            remove_high = st.checkbox("ç§»é™¤é«˜é » (6-12kHz) - é›»æ„Ÿå˜¯å«", value=False, key="rm_high")
            remove_ultra = st.checkbox("ç§»é™¤è¶…é«˜é » (12-20kHz)", value=False, key="rm_ultra")
            
            if remove_low:
                removed_bands.append("low_freq")
            if remove_mid:
                removed_bands.append("mid_freq")
            if remove_mid_high:
                removed_bands.append("mid_high_freq")
            if remove_high:
                removed_bands.append("high_freq")
            if remove_ultra:
                removed_bands.append("ultra_high_freq")
        
        st.markdown("---")
        st.subheader("ğŸ“„ å ±å‘Šç”Ÿæˆ (AUD-008)")
        
        if st.session_state.get('audio_loaded', False):
            if st.button("ğŸ“Š ç”Ÿæˆ Excel å ±å‘Š", key="btn_gen_report", use_container_width=True):
                with st.spinner("æ­£åœ¨å½™æ•´æ•¸æ“šä¸¦ç”Ÿæˆå ±å‘Š..."):
                    # ä½¿ç”¨åŸå§‹æœªéæ¿¾éŸ³è¨Š
                    report_data, error = generate_excel_report(
                        st.session_state.audio_original,
                        st.session_state.sr,
                        filename=st.session_state.get('audio_filename', "audio.wav")
                    )
                    
                    if error:
                        st.error(error)
                    else:
                        st.session_state['report_xlsx'] = report_data
                        st.success("âœ… å ±å‘Šç”ŸæˆæˆåŠŸ")

            if 'report_xlsx' in st.session_state:
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è¼‰ Excel å ±è¡¨",
                    data=st.session_state['report_xlsx'],
                    file_name=f"Report_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
        else:
            st.caption("è«‹å…ˆä¸Šå‚³éŸ³æª”ä»¥å•Ÿç”¨å ±å‘ŠåŠŸèƒ½")

        st.markdown("---")
        st.caption("v1.0.0 | è²å­¸æ¸¬è©¦ AI åˆ†æç³»çµ±")

    # ä¸»è¦å…§å®¹å€
    st.header("ğŸ“ ä¸Šå‚³éŸ³æª”")
    
    uploaded_files = st.file_uploader(
        "é¸æ“‡è¦åˆ†æçš„éŸ³æª” (æ”¯æ´å¤šé¸)",
        type=["wav", "mp3", "flac"],
        accept_multiple_files=True,
        help="æ”¯æ´ WAVã€MP3ã€FLAC æ ¼å¼ï¼Œæª”æ¡ˆå¤§å°ä¸Šé™ 50MB"
    )

    if uploaded_files:
        if len(uploaded_files) == 1:
            uploaded_file = uploaded_files[0]
            st.success(f"âœ… å·²ä¸Šå‚³: **{uploaded_file.name}** ({uploaded_file.size / 1024 / 1024:.2f} MB)")
            
            # é–‹å§‹åˆ†ææŒ‰éˆ• - åªè¼‰å…¥éŸ³æª”ä¸€æ¬¡
            if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True):
                load_audio_file(uploaded_file)
            
            # å¦‚æœéŸ³æª”å·²è¼‰å…¥ï¼Œæ ¹æ“šå´é‚Šæ¬„è¨­å®šå³æ™‚é¡¯ç¤ºåˆ†æçµæœ
            if st.session_state.audio_loaded:
                render_analysis_results(
                    highpass_cutoff,
                    analyze_noise,
                    analyze_spectrum,
                    analyze_discrete_tone,
                    analyze_high_freq,
                    analyze_band_filter,
                    removed_bands,
                    use_a_weighting,
                    spectrum_mode,
                    window_function
                )
        else:
            # æ‰¹æ¬¡æ¨¡å¼
            st.success(f"âœ… å·²ä¸Šå‚³ **{len(uploaded_files)}** å€‹æª”æ¡ˆï¼Œæº–å‚™é€²è¡Œæ‰¹æ¬¡åˆ†æ")
            if st.button(f"ğŸš€ é–‹å§‹æ‰¹æ¬¡åˆ†æ", type="primary", use_container_width=True):
                process_batch_analysis(uploaded_files)
            
            if st.session_state.get('batch_data'):
                render_batch_dashboard(
                    highpass_cutoff,
                    analyze_noise,
                    analyze_spectrum,
                    analyze_discrete_tone,
                    analyze_high_freq,
                    analyze_band_filter,
                    removed_bands,
                    use_a_weighting,
                    spectrum_mode,
                    window_function
                )
    else:
        # æ¸…é™¤å·²è¼‰å…¥çš„éŸ³æª”
        st.session_state.audio_loaded = False
        st.session_state.audio_original = None
        
        st.info("ğŸ‘† è«‹ä¸Šå‚³éŸ³æª”ä»¥é–‹å§‹åˆ†æ")
        
        # é¡¯ç¤ºæ”¯æ´çš„è¦æ ¼
        with st.expander("ğŸ“Œ æ”¯æ´çš„éŸ³æª”è¦æ ¼"):
            st.markdown("""
            | é …ç›® | è¦æ ¼ |
            |------|------|
            | æ ¼å¼ | WAV (å¿…é ˆ), MP3, FLAC (å¯é¸) |
            | å–æ¨£ç‡ | 44100 æˆ– 48000 Hz |
            | ä½å…ƒæ·±åº¦ | 16-bit æˆ– 24-bit |
            | è²é“ | Mono (å–®è²é“) |
            | æª”æ¡ˆå¤§å° | â‰¤ 50 MB |
            | é•·åº¦ | 10 - 120 ç§’ |
            """)


def load_audio_file(uploaded_file):
    """è¼‰å…¥éŸ³æª”åˆ° session_state"""
    with st.spinner("ğŸ”„ æ­£åœ¨è¼‰å…¥ä¸¦é©—è­‰éŸ³æª”..."):
        from core.audio_loader import load_audio, validate_audio
        
        # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(
            suffix=f".{uploaded_file.name.split('.')[-1]}",
            delete=False
        ) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        try:
            # é©—è­‰éŸ³æª”
            validation = validate_audio(tmp_path, strict=False)
            
            if not validation["file_valid"]:
                st.error(f"âŒ éŸ³æª”é©—è­‰å¤±æ•—: {validation['error_message']}")
                return
            
            # è¼‰å…¥éŸ³æª”
            audio, sr = load_audio(tmp_path)
            
            # ä¿å­˜åˆ° session_state
            st.session_state.audio_original = audio
            st.session_state.sr = sr
            st.session_state.validation = validation
            st.session_state.audio_loaded = True
            st.session_state.audio_filename = uploaded_file.name
            
            st.rerun()  # é‡æ–°é‹è¡Œä»¥é¡¯ç¤ºåˆ†æçµæœ
            
        finally:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            os.unlink(tmp_path)


def render_analysis_results(highpass_cutoff, analyze_noise, analyze_spectrum, 
                            analyze_discrete_tone, analyze_high_freq, 
                            analyze_band_filter, removed_bands, use_a_weighting=True,
                            spectrum_mode='average', window_function='hann'):
    """æ ¹æ“šå´é‚Šæ¬„è¨­å®šå³æ™‚æ¸²æŸ“åˆ†æçµæœ
    
    Args:
        highpass_cutoff: é«˜é€šæ¿¾æ³¢æˆªæ­¢é »ç‡
        analyze_noise: æ˜¯å¦åˆ†æå™ªéŸ³ç­‰ç´š
        analyze_spectrum: æ˜¯å¦åˆ†æé »è­œ
        analyze_discrete_tone: æ˜¯å¦æª¢æ¸¬ Discrete Tone
        analyze_high_freq: æ˜¯å¦åˆ†æé«˜é »
        analyze_band_filter: æ˜¯å¦å•Ÿç”¨é »å¸¶éæ¿¾
        removed_bands: è¦ç§»é™¤çš„é »å¸¶åˆ—è¡¨
        use_a_weighting: æ˜¯å¦å¥—ç”¨ A-weighting
        spectrum_mode: é »è­œåˆ†ææ¨¡å¼ (average/peak_hold/psd)
        window_function: çª—å‡½æ•¸ (hann/hamming/blackman/flattop)
    """
    import numpy as np
    import io
    import soundfile as sf
    
    # å¾ session_state å–å¾—éŸ³è¨Šè³‡æ–™
    audio_original = st.session_state.audio_original
    sr = st.session_state.sr
    validation = st.session_state.validation
    
    if audio_original is None:
        return
    
    # å¥—ç”¨é »å¸¶éæ¿¾ (å¦‚æœå•Ÿç”¨)
    if analyze_band_filter and removed_bands:
        with st.spinner("ğŸšï¸ å¥—ç”¨é »å¸¶éæ¿¾..."):
            audio = apply_band_filter(audio_original, sr, removed_bands)
            st.info(f"ğŸšï¸ **é »å¸¶éæ¿¾å·²å•Ÿç”¨**: å·²ç§»é™¤ {len(removed_bands)} å€‹é »å¸¶ï¼Œä»¥ä¸‹æ‰€æœ‰åˆ†æåŸºæ–¼éæ¿¾å¾Œçš„éŸ³è¨Š")
    else:
        audio = audio_original
    
    # é¡¯ç¤ºåŠ æ¬Šæ¨¡å¼
    # é¡¯ç¤ºåŠ æ¬Šæ¨¡å¼ (å·²ç§»é™¤å–®ç´”å±•ç¤º)
    pass
    
    # é¡¯ç¤ºéŸ³æª”è³‡è¨Š
    display_audio_info(validation)
    
    # === åŒæ­¥éŸ³è¨Šæ’­æ”¾å™¨ (å¸¶ Spectrogram é€²åº¦ç·š) ===
    from ui.audio_player import create_audio_player_with_spectrogram, create_simple_audio_player
    
    if analyze_band_filter and removed_bands:
        # æœ‰é »å¸¶éæ¿¾æ™‚é¡¯ç¤ºå…©å€‹æ’­æ”¾å™¨
        col1, col2 = st.columns(2)
        with col1:
            st.caption("ğŸ§ **éæ¿¾å¾ŒéŸ³è¨Š** (åŸºæ–¼æ­¤é€²è¡Œåˆ†æ)")
            create_audio_player_with_spectrogram(audio, sr, "ğŸµ éæ¿¾å¾ŒéŸ³è¨Šæ’­æ”¾å™¨")
        with col2:
            st.caption("ğŸ”Š **åŸå§‹éŸ³è¨Š** (å°ç…§åƒè€ƒ)")
            create_audio_player_with_spectrogram(audio_original, sr, "ğŸ”Š åŸå§‹éŸ³è¨Šæ’­æ”¾å™¨")
    else:
        # åªé¡¯ç¤ºä¸€å€‹æ’­æ”¾å™¨
        create_audio_player_with_spectrogram(audio, sr, "ğŸµ éŸ³è¨Šæ’­æ”¾å™¨ (é»æ“Šé »è­œåœ–å¯è·³è½‰)")
    
    st.markdown("---")
    
    # åŸ·è¡Œå„é …åˆ†æ (ä½¿ç”¨éæ¿¾å¾Œçš„éŸ³è¨Šï¼Œå‚³å…¥ A-weighting è¨­å®š)
    if analyze_noise:
        run_noise_analysis(audio, sr)

    if analyze_spectrum:
        run_spectrum_analysis(audio, sr, use_a_weighting, spectrum_mode, window_function)

    if analyze_discrete_tone:
        run_discrete_tone_analysis(audio, sr)

    if analyze_high_freq:
        run_high_freq_analysis(audio, sr, highpass_cutoff)

    # å¦‚æœæœ‰é »å¸¶éæ¿¾ï¼Œé¡¯ç¤ºåŸå§‹ vs éæ¿¾å¾Œå°æ¯”
    if analyze_band_filter and removed_bands:
        run_band_filter_comparison(audio_original, audio, sr, removed_bands)

    st.success("âœ… åˆ†æå®Œæˆï¼å´é‚Šæ¬„èª¿æ•´è¨­å®šæœƒå³æ™‚æ›´æ–°åœ–è¡¨ã€‚")



def display_audio_info(validation: dict):
    """é¡¯ç¤ºéŸ³æª”è³‡è¨Š"""
    st.subheader("ğŸ“Š éŸ³æª”è³‡è¨Š")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("å–æ¨£ç‡", f"{validation['sample_rate']} Hz")
    with col2:
        st.metric("é•·åº¦", f"{validation['duration']:.2f} ç§’")
    with col3:
        st.metric("ä½å…ƒæ·±åº¦", f"{validation['bit_depth']}-bit")
    with col4:
        st.metric("æª”æ¡ˆå¤§å°", f"{validation['file_size_mb']:.2f} MB")
    
    if validation.get("warnings"):
        for warning in validation["warnings"]:
            st.warning(f"âš ï¸ {warning}")


def run_noise_analysis(audio, sr):
    """åŸ·è¡Œå™ªéŸ³ç­‰ç´šåˆ†æ"""
    from core.noise_level import calculate_noise_level
    
    result = calculate_noise_level(audio, sr)
    
    st.subheader("ğŸ”Š å™ªéŸ³ç­‰ç´šåˆ†æ dB(A)")
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("Leq", f"{result['leq_dba']:.1f} dB")
    with col2:
        st.metric("Lmax", f"{result['lmax_dba']:.1f} dB")
    with col3:
        st.metric("Lmin", f"{result['lmin_dba']:.1f} dB")
    with col4:
        st.metric("L10", f"{result['l10']:.1f} dB")
    with col5:
        st.metric("L90", f"{result['l90']:.1f} dB")
    
    st.markdown("---")


def run_spectrum_analysis(audio, sr, use_a_weighting=True, 
                          spectrum_mode='average', window_function='hann'):
    """åŸ·è¡Œé »è­œåˆ†æ - å¤šç¨®åœ–è¡¨å³æ™‚åˆ‡æ›
    
    Args:
        audio: éŸ³è¨Šè³‡æ–™
        sr: å–æ¨£ç‡
        use_a_weighting: æ˜¯å¦å¥—ç”¨ A-weighting åŠ æ¬Š
        spectrum_mode: åˆ†ææ¨¡å¼ (average/peak_hold/psd)
        window_function: çª—å‡½æ•¸ (hann/hamming/blackman/flattop)
    """
    from core.fft import compute_spectrum_with_mode, apply_a_weighting
    from utils.interactive_plots import (
        create_interactive_spectrum,
        create_waveform_chart,
        create_spectrogram_chart,
        create_a_weighting_chart,
        create_octave_band_chart,
        create_waterfall_3d_chart,
        create_combined_analysis_chart
    )
    import numpy as np
    
    # åˆ†ææ¨¡å¼å°æ‡‰çš„æ¨™ç±¤
    mode_labels = {
        'average': 'FFT Average',
        'peak_hold': 'FFT Peak Hold',
        'psd': 'PSD'
    }
    mode_label = mode_labels.get(spectrum_mode, spectrum_mode)
    
    # ä½¿ç”¨æŒ‡å®šæ¨¡å¼å’Œçª—å‡½æ•¸è¨ˆç®—é »è­œ
    frequencies, magnitudes_db, unit = compute_spectrum_with_mode(
        audio, sr, mode=spectrum_mode, window=window_function
    )
    
    # å¥—ç”¨ A-weighting (å¦‚æœå•Ÿç”¨)
    if use_a_weighting:
        magnitudes_db = apply_a_weighting(frequencies, magnitudes_db)
        weight_label = f"{unit}(A)" if unit != 'dB/Hz' else "dB(A)/Hz"
    else:
        weight_label = unit
    
    # å°‡çµæœå­˜å…¥ session_state ä¾›åœ–è¡¨åˆ‡æ›ä½¿ç”¨
    st.session_state['audio'] = audio
    st.session_state['sr'] = sr
    st.session_state['frequencies'] = frequencies
    st.session_state['magnitudes_db'] = magnitudes_db
    st.session_state['use_a_weighting'] = use_a_weighting
    st.session_state['spectrum_mode'] = spectrum_mode
    st.session_state['window_function'] = window_function
    
    st.subheader(f"ğŸ“ˆ é »è­œåˆ†æ [{mode_label}] - {weight_label}")
    st.caption(f"ğŸ’¡ æ¨¡å¼: {mode_label} | çª—å‡½æ•¸: {window_function.capitalize()} | æ”¯æ´ç¸®æ”¾ã€å¹³ç§»ã€åå­—åº§æ¨™")
    
    # ä½¿ç”¨ tabs å¯¦ç¾å³æ™‚åˆ‡æ›
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        f"ğŸ“Š FFT é »è­œ ({weight_label})", 
        "ğŸŒŠ æ³¢å½¢åœ–", 
        "ğŸ”¥ Spectrogram", 
        f"ğŸ“¶ 1/3 å€é »ç¨‹ ({weight_label})",
        "ğŸŒ€ 3D Waterfall",
        "ğŸ“‹ ç¶œåˆè¦–åœ–"
    ])
    
    with tab1:
        spectrum_fig = create_interactive_spectrum(
            frequencies, magnitudes_db,
            title=f"FFT å¹³å‡é »è­œåœ– ({weight_label})",
            ylabel=f"å¹…åº¦ ({weight_label})"
        )
        st.plotly_chart(spectrum_fig, use_container_width=True, key="fft_spectrum")
    
    with tab2:
        waveform_fig = create_waveform_chart(audio, sr)
        st.plotly_chart(waveform_fig, use_container_width=True, key="waveform")
    
    with tab3:
        spectrogram_fig = create_spectrogram_chart(audio, sr)
        st.plotly_chart(spectrogram_fig, use_container_width=True, key="spectrogram")
    
    with tab4:
        octave_fig = create_octave_band_chart(audio, sr, use_a_weighting=use_a_weighting)
        st.plotly_chart(octave_fig, use_container_width=True, key="octave")
        st.info("ğŸ’¡ 1/3 å€é »ç¨‹åˆ†æä¾ IEC 61260 æ¨™æº–ï¼Œå°é½Š HEAD acoustics ArtemiS è¨ˆç®—æ–¹å¼ã€‚")
    
    with tab5:
        waterfall_fig = create_waterfall_3d_chart(audio, sr)
        st.plotly_chart(waterfall_fig, use_container_width=True, key="waterfall")
        st.info("ğŸ’¡ 3D Waterfall åœ–å¯æ—‹è½‰ã€ç¸®æ”¾ã€‚æ‹–æ›³å¯æ”¹è®Šè¦–è§’ï¼Œæ»¾è¼ªç¸®æ”¾ã€‚")
    
    with tab6:
        combined_fig = create_combined_analysis_chart(audio, sr, frequencies, magnitudes_db)
        st.plotly_chart(combined_fig, use_container_width=True, key="combined")
    
    st.markdown("---")


def run_discrete_tone_analysis(audio, sr):
    """åŸ·è¡Œ Discrete Tone æª¢æ¸¬"""
    from core.discrete_tone import detect_discrete_tones
    from core.fft import compute_average_spectrum, get_frequency_range
    from utils.interactive_plots import create_discrete_tone_chart
    
    result = detect_discrete_tones(audio, sr)
    
    st.subheader("ğŸµ Discrete Tone æª¢æ¸¬ (ECMA-74)")
    st.caption("ğŸ’¡ æç¤º: ç´…è‰²æ˜Ÿè™Ÿæ¨™è¨˜è¶…éé–€æª»çš„ Discrete Toneï¼Œç°è‰²ä¸‰è§’å½¢ç‚ºå€™é¸å³°å€¼")
    
    # è¨ˆç®—é »è­œç”¨æ–¼è¦–è¦ºåŒ–
    frequencies, magnitudes_db = compute_average_spectrum(audio, sr)
    frequencies, magnitudes_db = get_frequency_range(frequencies, magnitudes_db, 50, 15000)
    
    # ç¹ªè£½ Discrete Tone è¦–è¦ºåŒ–åœ–è¡¨
    tone_fig = create_discrete_tone_chart(
        frequencies, magnitudes_db,
        tones=result.get("tones", []),
        all_candidates=result.get("all_candidates", []),
        title="Discrete Tone æª¢æ¸¬çµæœ (ECMA-74 æ¨™æº–)"
    )
    st.plotly_chart(tone_fig, use_container_width=True)
    
    # ç‹€æ…‹é¡¯ç¤º
    if result["tone_detected"]:
        st.warning(f"âš ï¸ åµæ¸¬åˆ° {len(result['tones'])} å€‹ Discrete Tone!")
        
        # é¡¯ç¤ºåµæ¸¬åˆ°çš„ Tone
        for i, tone in enumerate(result["tones"], 1):
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric(f"Tone #{i} é »ç‡", f"{tone['frequency']:.0f} Hz")
            with col2:
                st.metric("çªå‡ºé‡", f"{tone['prominence']:.1f} dB")
            with col3:
                st.metric("é–€æª»", f"{tone['threshold']:.0f} dB")
            with col4:
                st.metric("é »å¸¶", tone['band'])
    else:
        st.success("âœ… æœªåµæ¸¬åˆ°è¶…éé–€æª»çš„ Discrete Tone")
    
    # é¡¯ç¤ºå€™é¸ Tone
    if result.get("all_candidates"):
        with st.expander("ğŸ” æŸ¥çœ‹æ‰€æœ‰å€™é¸å³°å€¼"):
            import pandas as pd
            df = pd.DataFrame(result["all_candidates"])
            if not df.empty:
                df.columns = ["é »ç‡ (Hz)", "çªå‡ºé‡ (dB)", "å¹…åº¦ (dB)", "é »å¸¶", "é–€æª» (dB)", "è¶…éé–€æª»"]
                st.dataframe(df, use_container_width=True)
    
    st.markdown("---")


def run_high_freq_analysis(audio, sr, cutoff):
    """åŸ·è¡Œé«˜é »éŸ³éš”é›¢åˆ†æ"""
    from core.high_freq_detector import analyze_high_frequency
    from core.fft import compute_average_spectrum, get_frequency_range
    from core.filters import highpass_filter
    from utils.interactive_plots import (
        create_comparison_spectrum,
        create_dual_spectrum_comparison,
        create_band_energy_chart
    )
    import numpy as np
    
    result = analyze_high_frequency(audio, sr, cutoff)
    
    st.subheader("âš¡ é«˜é »éŸ³éš”é›¢åˆ†æ")
    
    # æ•´é«”ç‹€æ…‹
    status = result["overall_status"]
    status_colors = {"PASS": "green", "WARNING": "orange", "FAIL": "red"}
    status_icons = {"PASS": "âœ…", "WARNING": "âš ï¸", "FAIL": "âŒ"}
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ•´é«”ç‹€æ…‹", f"{status_icons[status]} {status}")
    with col2:
        st.metric("æˆªæ­¢é »ç‡", f"{cutoff} Hz")
    with col3:
        coil_status = "åµæ¸¬åˆ°" if result["coil_whine_detected"] else "æœªåµæ¸¬"
        st.metric("é›»æ„Ÿå˜¯å«", coil_status)
    
    # é›»æ„Ÿå˜¯å«æª¢æ¸¬çµæœ
    if result["coil_whine_detected"]:
        st.error(
            f"ğŸ”” **åµæ¸¬åˆ°é›»æ„Ÿå˜¯å«!**\n\n"
            f"- é »ç‡: {result['coil_whine_frequency']:.0f} Hz\n"
            f"- çªå‡ºé‡: {result['coil_whine_prominence']:.1f} dB\n"
            f"- å¯èƒ½åŸå› : {result['possible_cause']}"
        )
    
    # å»ºè­°
    st.info(f"ğŸ’¡ **å»ºè­°:** {result['recommendation']}")
    
    # === æ¿¾æ³¢å‰å¾Œå°æ¯”åœ– (äº’å‹•å¼) ===
    st.subheader("ğŸ“Š æ¿¾æ³¢å‰å¾Œé »è­œå°æ¯” (å¯ç¸®æ”¾)")
    st.caption("ğŸ’¡ æç¤º: æ»‘é¼ æ»¾è¼ªç¸®æ”¾ã€æ‹–æ›³å¹³ç§»ã€é›™æ“Šé‡ç½®ã€æ»‘é¼ ç§»å‹•é¡¯ç¤ºåå­—åº§æ¨™")
    
    # è¨ˆç®—åŸå§‹é »è­œ
    freqs_orig, mags_orig = compute_average_spectrum(audio, sr)
    
    # è¨ˆç®—æ¿¾æ³¢å¾Œé »è­œ
    audio_filtered = highpass_filter(audio, sr, cutoff)
    freqs_filt, mags_filt = compute_average_spectrum(audio_filtered, sr)
    
    # é™åˆ¶é¡¯ç¤ºç¯„åœ
    freq_min, freq_max = 20, min(20000, sr // 2)
    freqs_orig, mags_orig = get_frequency_range(freqs_orig, mags_orig, freq_min, freq_max)
    freqs_filt, mags_filt = get_frequency_range(freqs_filt, mags_filt, freq_min, freq_max)
    
    # ç¹ªè£½äº’å‹•å¼å°æ¯”åœ–
    comparison_fig = create_comparison_spectrum(
        freqs_orig, mags_orig, mags_filt, cutoff,
        title=f"é«˜é€šæ¿¾æ³¢å‰å¾Œå°æ¯” (æˆªæ­¢é »ç‡: {cutoff} Hz)"
    )
    st.plotly_chart(comparison_fig, use_container_width=True)
    
    # åˆ†é–‹é¡¯ç¤ºåŸå§‹å’Œæ¿¾æ³¢å¾Œé »è­œ (äº’å‹•å¼é›™æ¬„)
    st.subheader("ğŸ“ˆ åŸå§‹ vs æ¿¾æ³¢å¾Œé »è­œå°æ¯”")
    dual_fig = create_dual_spectrum_comparison(
        freqs_orig, mags_orig,
        freqs_filt, mags_filt,
        title1="åŸå§‹é »è­œ (å…¨é »å¸¶)",
        title2=f"é«˜é€šæ¿¾æ³¢å¾Œ (>{cutoff} Hz)"
    )
    st.plotly_chart(dual_fig, use_container_width=True)
    
    # é »å¸¶èƒ½é‡åˆ†æåœ– (äº’å‹•å¼)
    st.subheader("ğŸ“Š é »å¸¶èƒ½é‡åˆ†æ")
    if result.get("band_analysis"):
        band_fig = create_band_energy_chart(result["band_analysis"])
        st.plotly_chart(band_fig, use_container_width=True)
    
    # é«˜é »å³°å€¼åˆ—è¡¨
    if result.get("high_freq_peaks"):
        with st.expander("ğŸ” æŸ¥çœ‹é«˜é »å³°å€¼è©³æƒ…"):
            import pandas as pd
            peaks_df = pd.DataFrame(result["high_freq_peaks"])
            if not peaks_df.empty:
                peaks_df.columns = ["é »ç‡ (Hz)", "å¹…åº¦ (dB)", "çªå‡ºé‡ (dB)"]
                st.dataframe(peaks_df, use_container_width=True)
            else:
                st.info("ç„¡æ˜é¡¯é«˜é »å³°å€¼")
    
    st.markdown("---")


def run_band_filter_analysis(audio, sr, removed_bands):
    """åŸ·è¡Œé »å¸¶éæ¿¾æ¨¡æ“¬åˆ†æ"""
    from core.fft import compute_average_spectrum, get_frequency_range
    from core.filters import bandpass_filter
    from core.noise_level import calculate_rms, rms_to_db
    from utils.interactive_plots import create_band_filter_comparison
    import numpy as np
    
    st.subheader("ğŸšï¸ é »å¸¶éæ¿¾æ¨¡æ“¬")
    st.caption("æ¨¡æ“¬ç§»é™¤ç‰¹å®šé »å¸¶å¾Œçš„é »è­œè®ŠåŒ–")
    
    # é »å¸¶å®šç¾©
    band_ranges = {
        'low_freq': (20, 500),
        'mid_freq': (500, 2000),
        'mid_high_freq': (2000, 6000),
        'high_freq': (6000, 12000),
        'ultra_high_freq': (12000, 20000)
    }
    
    band_names = {
        'low_freq': 'ä½é » (é¢¨æ‰‡/é¦¬é”)',
        'mid_freq': 'ä¸­é » (æ©Ÿæ¢°é‹è½‰)',
        'mid_high_freq': 'ä¸­é«˜é » (éµç›¤è²)',
        'high_freq': 'é«˜é » (é›»æ„Ÿå˜¯å«)',
        'ultra_high_freq': 'è¶…é«˜é »'
    }
    
    # é¡¯ç¤ºç§»é™¤çš„é »å¸¶
    st.info(f"ğŸ”‡ å·²ç§»é™¤çš„é »å¸¶: {', '.join([band_names.get(b, b) for b in removed_bands])}")
    
    # è¨ˆç®—åŸå§‹é »è­œ
    freqs_orig, mags_orig = compute_average_spectrum(audio, sr)
    
    # å»ºç«‹éæ¿¾å¾Œçš„è¨Šè™Ÿ (é€šéä¿ç•™æœªè¢«ç§»é™¤çš„é »å¸¶)
    nyquist = sr / 2
    audio_filtered = np.zeros_like(audio)
    
    for band_name, (low, high) in band_ranges.items():
        if band_name not in removed_bands:
            # ç¢ºä¿é »ç‡åœ¨æœ‰æ•ˆç¯„åœå…§
            low = max(20, low)
            high = min(high, nyquist - 1)
            if low < high:
                try:
                    band_audio = bandpass_filter(audio, sr, low, high)
                    audio_filtered += band_audio
                except:
                    pass
    
    # è¨ˆç®—éæ¿¾å¾Œé »è­œ
    freqs_filt, mags_filt = compute_average_spectrum(audio_filtered, sr)
    
    # é™åˆ¶é¡¯ç¤ºç¯„åœ
    freq_min, freq_max = 20, min(20000, sr // 2)
    freqs_orig, mags_orig = get_frequency_range(freqs_orig, mags_orig, freq_min, freq_max)
    freqs_filt, mags_filt = get_frequency_range(freqs_filt, mags_filt, freq_min, freq_max)
    
    # ç¹ªè£½äº’å‹•å¼å°æ¯”åœ–
    filter_fig = create_band_filter_comparison(
        freqs_orig, mags_orig, mags_filt, removed_bands,
        title="é »å¸¶éæ¿¾å‰å¾Œå°æ¯”"
    )
    st.plotly_chart(filter_fig, use_container_width=True)
    
    # è¨ˆç®—èƒ½é‡è®ŠåŒ–
    col1, col2, col3 = st.columns(3)
    
    rms_orig = calculate_rms(audio)
    rms_filt = calculate_rms(audio_filtered)
    db_orig = rms_to_db(rms_orig, 1.0)
    db_filt = rms_to_db(rms_filt, 1.0)
    db_reduction = db_orig - db_filt
    
    with col1:
        st.metric("åŸå§‹èƒ½é‡", f"{db_orig:.1f} dB")
    with col2:
        st.metric("éæ¿¾å¾Œèƒ½é‡", f"{db_filt:.1f} dB")
    with col3:
        st.metric("èƒ½é‡é™ä½", f"{db_reduction:.1f} dB", delta=f"-{db_reduction:.1f}")
    
    st.markdown("---")


def apply_band_filter(audio, sr, removed_bands):
    """å¥—ç”¨é »å¸¶éæ¿¾ï¼Œç§»é™¤æŒ‡å®šé »å¸¶
    
    Args:
        audio: åŸå§‹éŸ³è¨Šè³‡æ–™
        sr: å–æ¨£ç‡
        removed_bands: è¦ç§»é™¤çš„é »å¸¶åˆ—è¡¨
    
    Returns:
        éæ¿¾å¾Œçš„éŸ³è¨Šè³‡æ–™
    """
    from core.filters import bandpass_filter
    import numpy as np
    
    # é »å¸¶å®šç¾©
    band_ranges = {
        'low_freq': (20, 500),
        'mid_freq': (500, 2000),
        'mid_high_freq': (2000, 6000),
        'high_freq': (6000, 12000),
        'ultra_high_freq': (12000, 20000)
    }
    
    nyquist = sr / 2
    audio_filtered = np.zeros_like(audio)
    
    # åªä¿ç•™æœªè¢«ç§»é™¤çš„é »å¸¶
    for band_name, (low, high) in band_ranges.items():
        if band_name not in removed_bands:
            low = max(20, low)
            high = min(high, nyquist - 1)
            if low < high:
                try:
                    band_audio = bandpass_filter(audio, sr, low, high)
                    audio_filtered += band_audio
                except:
                    pass
    
    return audio_filtered


def run_band_filter_comparison(audio_original, audio_filtered, sr, removed_bands):
    """é¡¯ç¤ºåŸå§‹èˆ‡éæ¿¾å¾Œçš„é »è­œå°æ¯”"""
    from core.fft import compute_average_spectrum, get_frequency_range
    from core.noise_level import calculate_rms, rms_to_db
    from utils.interactive_plots import create_band_filter_comparison
    
    st.subheader("ğŸšï¸ é »å¸¶éæ¿¾æ•ˆæœå°æ¯”")
    
    band_names = {
        'low_freq': 'ä½é » (é¢¨æ‰‡/é¦¬é”)',
        'mid_freq': 'ä¸­é » (æ©Ÿæ¢°é‹è½‰)',
        'mid_high_freq': 'ä¸­é«˜é » (éµç›¤è²)',
        'high_freq': 'é«˜é » (é›»æ„Ÿå˜¯å«)',
        'ultra_high_freq': 'è¶…é«˜é »'
    }
    
    st.info(f"ğŸ”‡ å·²ç§»é™¤çš„é »å¸¶: {', '.join([band_names.get(b, b) for b in removed_bands])}")
    
    # è¨ˆç®—åŸå§‹å’Œéæ¿¾å¾Œé »è­œ
    freqs_orig, mags_orig = compute_average_spectrum(audio_original, sr)
    freqs_filt, mags_filt = compute_average_spectrum(audio_filtered, sr)
    
    freq_min, freq_max = 20, min(20000, sr // 2)
    freqs_orig, mags_orig = get_frequency_range(freqs_orig, mags_orig, freq_min, freq_max)
    freqs_filt, mags_filt = get_frequency_range(freqs_filt, mags_filt, freq_min, freq_max)
    
    # ç¹ªè£½å°æ¯”åœ–
    filter_fig = create_band_filter_comparison(
        freqs_orig, mags_orig, mags_filt, removed_bands,
        title="åŸå§‹é »è­œ vs éæ¿¾å¾Œé »è­œ"
    )
    st.plotly_chart(filter_fig, use_container_width=True)
    
    # èƒ½é‡è®ŠåŒ–
    col1, col2, col3 = st.columns(3)
    
    rms_orig = calculate_rms(audio_original)
    rms_filt = calculate_rms(audio_filtered)
    db_orig = rms_to_db(rms_orig, 1.0)
    db_filt = rms_to_db(rms_filt, 1.0)
    db_reduction = db_orig - db_filt
    
    with col1:
        st.metric("åŸå§‹èƒ½é‡", f"{db_orig:.1f} dB")
    with col2:
        st.metric("éæ¿¾å¾Œèƒ½é‡", f"{db_filt:.1f} dB")
    with col3:
        st.metric("èƒ½é‡é™ä½", f"{db_reduction:.1f} dB", delta=f"-{db_reduction:.1f}")
    
    st.markdown("---")


def process_batch_analysis(uploaded_files):
    """åŸ·è¡Œæ‰¹æ¬¡åˆ†æ"""
    import pandas as pd
    import tempfile
    import os
    from core.audio_loader import load_audio, validate_audio
    from core.noise_level import calculate_noise_level
    from core.fft import compute_average_spectrum
    from core.high_freq_detector import analyze_high_frequency
    from core.band_analyzer import compute_octave_bands
    
    batch_results = {}
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    count = len(uploaded_files)
    
    for i, file in enumerate(uploaded_files):
        status_text.text(f"æ­£åœ¨åˆ†æ ({i+1}/{count}): {file.name}...")
        
        # Save temp
        suffix = f".{file.name.split('.')[-1]}"
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp.write(file.getvalue())
            tmp_path = tmp.name
            
        try:
            # 1. Validate Audio
            validation = validate_audio(tmp_path, strict=False)
            
            # 2. Load Audio
            audio, sr = load_audio(tmp_path)
            
            # 3. Noise Level
            noise = calculate_noise_level(audio, sr)
            
            # 4. High Freq
            hf = analyze_high_frequency(audio, sr)
            
            # 5. Spectrum
            freqs, mags = compute_average_spectrum(audio, sr)
            
            # 6. 1/3 Octave Bands
            octave = compute_octave_bands(audio, sr, use_a_weighting=True)
            
            # Store Result
            batch_results[file.name] = {
                "noise": noise,
                "high_freq": hf,
                "spectrum": {"freqs": freqs, "mags": mags},
                "octave": octave,
                "sr": sr,
                "duration": len(audio)/sr,
                "audio": audio, # Save raw audio
                "validation": validation # Save validation info
            }
            
        except Exception as e:
            st.error(f"åˆ†æ {file.name} å¤±æ•—: {e}")
            
        finally:
            try:
                os.unlink(tmp_path)
            except:
                pass
            
        progress_bar.progress((i + 1) / count)
        
    st.session_state['batch_data'] = batch_results
    status_text.success("æ‰¹æ¬¡åˆ†æå®Œæˆ!")
    st.rerun()


def render_batch_dashboard(
    highpass_cutoff,
    analyze_noise,
    analyze_spectrum,
    analyze_discrete_tone,
    analyze_high_freq,
    analyze_band_filter,
    removed_bands,
    use_a_weighting,
    spectrum_mode,
    window_function
):
    """é¡¯ç¤ºæ‰¹æ¬¡åˆ†æå„€è¡¨æ¿"""
    import plotly.graph_objects as go
    
    data = st.session_state.get('batch_data', {})
    if not data:
        return

    st.header("ğŸ“Š æ‰¹æ¬¡åˆ†ææ¯”è¼ƒå„€è¡¨æ¿")
    
    # 1. Comparison Table
    st.subheader("1. æ•¸æ“šç¸½è¡¨")
    table_rows = []
    
    for name, res in data.items():
        n = res['noise']
        hf = res['high_freq']
        table_rows.append({
            "Filename": name,
            "Leq (dBA)": n['leq_dba'],
            "Lmax": n['lmax_dba'],
            "L90": n['l90'],
            "Coil Whine": "YES" if hf['coil_whine_detected'] else "NO",
            "CW Freq": f"{hf.get('coil_whine_frequency', 0):.0f}" if hf['coil_whine_detected'] else "-",
            "CW Prom": f"{hf.get('coil_whine_prominence', 0):.1f}" if hf['coil_whine_detected'] else "-"
        })
    
    import pandas as pd
    df = pd.DataFrame(table_rows)
    st.dataframe(df, use_container_width=True)
    
    st.download_button(
        label="â¬‡ï¸ ä¸‹è¼‰æ¯”è¼ƒç¸½è¡¨ (CSV)",
        data=df.to_csv(index=False).encode('utf-8-sig'),
        file_name=f"Batch_Summary_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
        mime="text/csv"
    )
    

    # File Selector for Comparison Charts
    st.subheader("2. è©³ç´°æ¯”è¼ƒåˆ†æ")
    st.caption("å»ºè­°é¸æ“‡ 2-3 å€‹æª”æ¡ˆé€²è¡Œè©³ç´°æ¯”è¼ƒï¼Œä»¥å…ç•«é¢éæ–¼æ“æ“ ")
    selected_files = st.multiselect("é¸æ“‡è¦æ¯”è¼ƒçš„æª”æ¡ˆ", options=list(data.keys()), default=list(data.keys())[:2])
    
    if not selected_files:
        st.info("è«‹é¸æ“‡è‡³å°‘ä¸€å€‹æª”æ¡ˆé€²è¡Œæ¯”è¼ƒ")
        return

    # Import visualization tools
    from utils.interactive_plots import (
        create_spectrogram_chart,
        create_waterfall_3d_chart,
        create_octave_band_chart
    )
    
    # 1. 1/3 Octave Comparison (Grouped Bar)
    st.markdown("#### 1/3 å€é »ç¨‹æ¯”è¼ƒ (Grouped Bar)")
    fig_oct = go.Figure()
    
    for name in selected_files:
        oct_data = data[name]['octave']
        # Use Bar for grouped comparison
        fig_oct.add_trace(go.Bar(
            x=oct_data['nominal_freqs'],
            y=oct_data['band_levels'],
            name=name,
            opacity=0.8
        ))
        
    fig_oct.update_layout(
        title="1/3 å€é »ç¨‹é »è­œæ¯”è¼ƒ",
        xaxis_title="é »ç‡ (Hz)",
        yaxis_title="éŸ³å£“ç´š dB(A)",
        xaxis_type="log",
        barmode='group', # Grouped bars
        hovermode="x unified"
    )
    st.plotly_chart(fig_oct, use_container_width=True)

    # 2. FFT Comparison (Line)
    st.markdown("#### FFT ç´°éƒ¨é »è­œæ¯”è¼ƒ (Overlay)")
    fig_fft = go.Figure()
    for name in selected_files:
        spec = data[name]['spectrum']
        mask = spec['freqs'] <= 20000
        x_vals = spec['freqs'][mask]
        y_vals = spec['mags'][mask]
        
        fig_fft.add_trace(go.Scatter(
            x=x_vals, 
            y=y_vals,
            name=name,
            mode='lines',
            line=dict(width=1)
        ))
    fig_fft.update_layout(
        title="FFT å¹³å‡é »è­œæ¯”è¼ƒ",
        xaxis_title="é »ç‡ (Hz)",
        yaxis_title="å¹…åº¦ (dB)",
        hovermode="x unified",
        xaxis_type="log"
    )
    st.plotly_chart(fig_fft, use_container_width=True)
    
    # 3. Level vs Time
    st.markdown("#### å™ªéŸ³ç­‰ç´šè¶¨å‹¢ (Level vs Time)")
    fig_time = go.Figure()
    has_profile = False
    
    for name in selected_files:
        profile = data[name]['noise'].get('profile', {})
        if profile and 'times' in profile and 'levels' in profile:
            has_profile = True
            times = profile['times']
            levels = profile['levels']
            if len(times) > 5000:
                step = len(times) // 5000
                times = times[::step]
                levels = levels[::step]
            
            fig_time.add_trace(go.Scatter(
                x=times, 
                y=levels,
                name=name,
                mode='lines',
                line=dict(width=1.5)
            ))
            
    if has_profile:
        fig_time.update_layout(
            title="å™ªéŸ³ç­‰ç´šè¶¨å‹¢æ¯”è¼ƒ (Leq Profile)",
            xaxis_title="æ™‚é–“ (ç§’)",
            yaxis_title="éŸ³å£“ç´š dB(A)",
            hovermode="x unified"
        )
        st.plotly_chart(fig_time, use_container_width=True)

    # 4. Spectrogram Comparison (Side-by-side)
    st.markdown("#### Spectrogram å°ç…§æ¯”è¼ƒ")
    cols = st.columns(len(selected_files))
    for i, name in enumerate(selected_files):
        with cols[i]:
            st.markdown(f"**{name}**")
            audio_data = data[name].get('audio', None)
            sr_data = data[name].get('sr', 48000)
            if audio_data is not None:
                # Reuse existing function
                fig_spec = create_spectrogram_chart(audio_data, sr_data, title=f"Spectrogram: {name}")
                st.plotly_chart(fig_spec, use_container_width=True, key=f"batch_spec_{i}")
            else:
                st.warning("ç„¡éŸ³è¨Šæ•¸æ“š")

    # 5. 3D Waterfall Comparison (Side-by-side)
    st.markdown("#### 3D Waterfall å°ç…§æ¯”è¼ƒ")
    cols_water = st.columns(len(selected_files))
    for i, name in enumerate(selected_files):
        with cols_water[i]:
            st.markdown(f"**{name}**")
            audio_data = data[name].get('audio', None)
            sr_data = data[name].get('sr', 48000)
            if audio_data is not None:
                fig_water = create_waterfall_3d_chart(audio_data, sr_data)
                # Update title
                fig_water.update_layout(title=f"Waterfall: {name}")
                st.plotly_chart(fig_water, use_container_width=True, key=f"batch_water_{i}")
            else:
                st.warning("ç„¡éŸ³è¨Šæ•¸æ“š")

        
    # --- Detail Inspector ---
    st.markdown("---")
    st.header("ğŸ” å–®æª”è©³ç´°åˆ†ææª¢è¦– (Detail Inspector)")
    
    detail_file = st.selectbox("é¸æ“‡è¦æŸ¥çœ‹è©³ç´°å ±å‘Šçš„æª”æ¡ˆ", options=["(è«‹é¸æ“‡)"] + list(data.keys()))
    
    if detail_file and detail_file != "(è«‹é¸æ“‡)":
        target_data = data[detail_file]
        
        # Inject data into global session state to simulate Single File Mode
        st.session_state.audio_loaded = True
        st.session_state.audio_original = target_data['audio']
        st.session_state.sr = target_data['sr']
        st.session_state.audio_filename = detail_file
        # Fix: Inject validation info
        if 'validation' in target_data:
            st.session_state.validation = target_data['validation']
        else:
            # Fallback if old data present in session (should not happen if re-run)
            st.session_state.validation = {
                "file_valid": True,
                "sample_rate": target_data['sr'],
                "duration": target_data['duration'],
                "channels": 1,
                "bit_depth": 16, # Assume 16
                "file_size_mb": 0,
                "warnings": []
            }
        
        st.info(f"æ­£åœ¨é¡¯ç¤º **{detail_file}** çš„è©³ç´°åˆ†æçµæœ...")
        
        # Reuse the main analysis renderer
        # Ensure we capture current sidebar settings
        # We need to access the sidebar widget values. They are in 'main' scope...
        # But Streamlit widgets are global in session_state usually.
        # However, variables like 'highpass_cutoff' are passed as args.
        # We need to grab them from session_state or default?
        # Sidebar widgets were defined in 'main()'. They are local variables there.
        # WE CANNOT ACCESS 'highpass_cutoff' here easily unless we pass them or read session state keys.
        
        render_analysis_results(
            highpass_cutoff,
            analyze_noise,
            analyze_spectrum,
            analyze_discrete_tone,
            analyze_high_freq,
            analyze_band_filter,
            removed_bands,
            use_a_weighting,
            spectrum_mode,
            window_function
        )



if __name__ == "__main__":
    main()


